{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EASY - 4-study analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "\n",
    "import imageio\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from isicarchive import font, func, imfunc\n",
    "from isicarchive.api import IsicApi\n",
    "\n",
    "# function for mean and sample STD\n",
    "def mean_std(a:list, is_sample:bool=True):\n",
    "    ddof = 1 if is_sample else 0\n",
    "    return (numpy.mean(a), numpy.std(a, ddof=ddof))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings\n",
    "single_study = False # process a single study (set to false for all studies)\n",
    "study_number = '1' # which study to process\n",
    "up_to_study = 4 # what's the last study (if multiple)\n",
    "\n",
    "print_details = True # set to True for details in the print-out\n",
    "print_fine_details = False # for even more details\n",
    "\n",
    "heatmap_mix_colors = False # set to True for mixed rather than striped patches\n",
    "heatmap_underlay_gray = 0.8 # remove this much color from images for heatmaps\n",
    "heatmap_resize_output = 4096 # set heatmap output size (prior to montage)\n",
    "heatmap_legend_font_size = 144.0 # legend font-size (default, prior to fitting)\n",
    "heatmap_single_colors = True # legends only have single-feature patches\n",
    "\n",
    "overlap_compute_smcc = False # also compute smoothed-cross-correlation (masks)\n",
    "overlap_colormap = 'Greys' # colormap for overlap confusion matrices\n",
    "overlap_blow_up = 24 # blow-up factor (for each cell)\n",
    "\n",
    "sp_minpairs = 3\n",
    "sp_diag_minpairs = 2\n",
    "sp_thresh_min = 2.0 / 3.0\n",
    "sp_thresh_max = 3.0 / 2.0\n",
    "sp_list_thresh = 0.5\n",
    "\n",
    "calibri = font.Font('calibri') # font to use (currently only one available!)\n",
    "\n",
    "# please change the username if you wish to re-run the notebook!\n",
    "username = 'weberj3@mskcc.org'\n",
    "\n",
    "# root folder for all ISIC related data\n",
    "doc_folder = 'Z:\\\\10.Imaging Informatics\\\\'\n",
    "\n",
    "# cache folder\n",
    "cache_folder = doc_folder + 'ISIC' + os.sep + 'cache'\n",
    "\n",
    "# show URL requests (for debugging purposes)\n",
    "debug = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate API object\n",
    "api = IsicApi(username, cache_folder=cache_folder, debug=debug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single study?\n",
    "if single_study:\n",
    "    # study number and folder\n",
    "    study_folder = doc_folder + 'EASY' + os.sep + 'STUDY_' + study_number + os.sep\n",
    "    \n",
    "    # load single study and data\n",
    "    study = api.study('EASY_STUDY_' + study_number)\n",
    "    study.cache_image_data()\n",
    "    study.load_annotations()\n",
    "else:\n",
    "    # study folder\n",
    "    study_folder = doc_folder + 'EASY' + os.sep + 'STUDY_1to4' + os.sep\n",
    "    studies = [None] * up_to_study\n",
    "\n",
    "    # load set of studies and data\n",
    "    for c in range(1, up_to_study+1):\n",
    "        study = api.study('EASY_STUDY_' + str(c))\n",
    "        study.cache_image_data()\n",
    "        study.load_annotations()\n",
    "        studies[c-1] = study\n",
    "\n",
    "    # combine studies\n",
    "    study = api.combine_studies(studies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single study?\n",
    "if single_study:\n",
    "    meta_data_url = study_folder + 'study' + study_number + '.csv'\n",
    "    study_part = study_number\n",
    "else:\n",
    "    meta_data_url = study_folder + 'studies.csv'\n",
    "    study_part = '1to' + str(up_to_study)\n",
    "\n",
    "# load meta data\n",
    "study.load_meta_data(meta_data_url, list_to_dict=True,\n",
    "    dict_key='ISIC_id', extract_key=['exemplar', 'group', 'benign_malignant', 'diagnosis'])\n",
    "\n",
    "# same for exemplar features\n",
    "exem_images = dict()\n",
    "for (name, exemplar) in study.meta_data['exemplar'].items():\n",
    "    if not exemplar:\n",
    "        continue\n",
    "    if not exemplar in exem_images:\n",
    "        exem_images[exemplar] = []\n",
    "    exem_images[exemplar].append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select only from users that completed the study\n",
    "image_names = [img['name'] for img in study.images]\n",
    "num_images = 62 # fixed number\n",
    "users = [u for (u,c) in study.user_completion.items() if c==num_images]\n",
    "study.select_annotations(users=users)\n",
    "user_names = {u['_id']: u['name'].replace('User ', '') for u in study.users}\n",
    "user_fullnames = {u['_id']: u['firstName'] + ' ' + u['lastName'] for u in study.users}\n",
    "user_idx = dict()\n",
    "for (idx, u) in enumerate(users):\n",
    "    user_idx[u] = idx\n",
    "\n",
    "# number of all annotations (across users, images, features)\n",
    "total_features_annotations = sum(\n",
    "    [len(a.features) for a in study.annotation_selection.values()])\n",
    "\n",
    "# determine which features were used\n",
    "selected_features = dict()\n",
    "for annotation in study.annotation_selection.values():\n",
    "    for feature in annotation.features:\n",
    "        selected_features[feature] = True\n",
    "\n",
    "# and create necessary lists\n",
    "full_features_list = sorted(list([f['id'] for f in study.features]))\n",
    "features_list = sorted(selected_features.keys())\n",
    "num_features = len(features_list)\n",
    "features_idx = dict()\n",
    "for (feat_idx, feat_name) in enumerate(features_list):\n",
    "    features_idx[feat_name] = feat_idx\n",
    "category_list = sorted(list(set([v.split(' : ')[0] for v in features_list])))\n",
    "num_categories = len(category_list)\n",
    "category_idx = dict()\n",
    "for (cat_idx, cat_name) in enumerate(category_list):\n",
    "    category_idx[cat_name] = cat_idx\n",
    "\n",
    "# determine which features were used per (main) diagnosis\n",
    "melanoma_features = []\n",
    "nevus_features = []\n",
    "melanoma_im_features = {name: [] for name in image_names}\n",
    "nevus_im_features = {name: [] for name in image_names}\n",
    "for annotation in study.annotation_selection.values():\n",
    "    nf = len(annotation.features)\n",
    "    if nf == 0:\n",
    "        continue\n",
    "    name = annotation.image['name']\n",
    "    ai_bm = study.meta_data['benign_malignant'][name]\n",
    "    ai_mn = study.meta_data['diagnosis'][name]\n",
    "    if ai_bm == 'malignant' and ai_mn[0] == 'm':\n",
    "        melanoma_features.append(nf)\n",
    "        melanoma_im_features[name].append(nf)\n",
    "    elif ai_bm == 'benign' and ai_mn[0] == 'n':\n",
    "        nevus_features.append(nf)\n",
    "        nevus_im_features[name].append(nf)\n",
    "mf_mean_std = mean_std(melanoma_features)\n",
    "nf_mean_std = mean_std(nevus_features)\n",
    "for name in image_names:\n",
    "    if len(melanoma_im_features[name]) == 0:\n",
    "        del melanoma_im_features[name]\n",
    "    else:\n",
    "        melanoma_im_features[name] = mean_std(melanoma_im_features[name])[0]\n",
    "    if len(nevus_im_features[name]) == 0:\n",
    "        del nevus_im_features[name]\n",
    "    else:\n",
    "        nevus_im_features[name] = mean_std(nevus_im_features[name])[0]\n",
    "mif_mean_std = mean_std(list(melanoma_im_features.values()))\n",
    "nif_mean_std = mean_std(list(nevus_im_features.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create full annotation log CSV file\n",
    "akeys = list(study.annotation_selection.keys())\n",
    "atimes = list()\n",
    "auid = list()\n",
    "auser = list()\n",
    "aimage = list()\n",
    "atype = list()\n",
    "adetail = list()\n",
    "aexemplar = list()\n",
    "for a in akeys:\n",
    "    aobj = study.annotation_selection[a]\n",
    "    au = aobj.user_id\n",
    "    aun = user_fullnames[au]\n",
    "    ai = aobj.image['name']\n",
    "    alog = aobj.log\n",
    "    aex = study.meta_data['exemplar'][ai]\n",
    "    for l in alog:\n",
    "        atimes.append(l['time'])\n",
    "        auid.append(au)\n",
    "        auser.append(aun)\n",
    "        aimage.append(ai)\n",
    "        atype.append(l['type'])\n",
    "        adetail.append(l['detail'])\n",
    "        aexemplar.append(aex)\n",
    "ainfo = {\n",
    "    'time': atimes,\n",
    "    'uid': auid,\n",
    "    'username': auser,\n",
    "    'image': aimage,\n",
    "    'type': atype,\n",
    "    'detail': adetail,\n",
    "    'exemplar': aexemplar,\n",
    "}\n",
    "api.write_csv('annotation_log.csv', ainfo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an optional cell (for heatmaps and overlap statistics; the\n",
    "results of which are needed for some cells below, but the computation\n",
    "takes a lot of time, so it's split out into a separate cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create heatmaps with default settings (if not yet done, about 30 minutes)\n",
    "study_stats_file = study_folder + 'heatmap_stats.json.gz'\n",
    "if not os.path.exists(study_stats_file):\n",
    "    study_stats = study.image_heatmaps(study_folder, users=users,\n",
    "        mix_colors=heatmap_mix_colors, underlay_gray=heatmap_underlay_gray, \n",
    "        resize_output=heatmap_resize_output, font_size=heatmap_legend_font_size,\n",
    "        single_colors=heatmap_single_colors)\n",
    "else:\n",
    "    study_stats = func.gzip_load_var(study_stats_file)\n",
    "\n",
    "# compute feature overlap stats\n",
    "overlap_stats_file = study_folder + 'overlap_features.npz'\n",
    "if not os.path.exists(overlap_stats_file):\n",
    "    overlap_stats = study.overlap_stats(users=users, \n",
    "        compute_smcc=overlap_compute_smcc)\n",
    "    overlap_features_dice = overlap_stats[4]\n",
    "    overlap_feat_cat_dice = overlap_stats[6]\n",
    "    overlap_category_dice = overlap_stats[8]\n",
    "    if overlap_compute_smcc:\n",
    "        overlap_features_smcc = overlap_stats[10]\n",
    "        overlap_feat_cat_smcc = overlap_stats[12]\n",
    "        overlap_category_smcc = overlap_stats[14]\n",
    "        numpy.savez(overlap_stats_file,\n",
    "            overlap_features_dice=overlap_features_dice,\n",
    "            overlap_feat_cat_dice=overlap_feat_cat_dice,\n",
    "            overlap_category_dice=overlap_category_dice,\n",
    "            overlap_features_smcc=overlap_features_smcc,\n",
    "            overlap_feat_cat_smcc=overlap_feat_cat_smcc,\n",
    "            overlap_category_smcc=overlap_category_smcc)\n",
    "    else:\n",
    "        numpy.savez(overlap_stats_file,\n",
    "            overlap_features_dice=overlap_features_dice,\n",
    "            overlap_feat_cat_dice=overlap_feat_cat_dice,\n",
    "            overlap_category_dice=overlap_category_dice)\n",
    "overlap_stats = numpy.load(overlap_stats_file)\n",
    "overlap_features_dice = overlap_stats.get('overlap_features_dice')\n",
    "overlap_feat_cat_dice = overlap_stats.get('overlap_feat_cat_dice')\n",
    "overlap_category_dice = overlap_stats.get('overlap_category_dice')\n",
    "if 'overlap_features_smcc' in overlap_stats.keys():\n",
    "    overlap_compute_smcc = True\n",
    "if overlap_compute_smcc:\n",
    "    try:\n",
    "        overlap_features_smcc = overlap_stats.get('overlap_features_smcc')\n",
    "        overlap_feat_cat_smcc = overlap_stats.get('overlap_feat_cat_smcc')\n",
    "        overlap_category_smcc = overlap_stats.get('overlap_category_smcc')\n",
    "    except:\n",
    "        overlap_compute_smcc = False\n",
    "\n",
    "# select those annotations, and gather basic statistics\n",
    "selected_annotations = study.select_annotations(users=users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives some basic statistics of the study:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{1:d} readers annotated the {2:d} dermoscopic images.'.format(\n",
    "    study.name, len(users), len(study.images)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Out of {0:d} offered features, {1:d} were selected at least once.'.format(\n",
    "    len(study.features), len(selected_features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Each reader annotated an average of {0:.1f} features per lesion.'.format(\n",
    "    float(total_features_annotations) / len(study.annotation_selection)))\n",
    "print('In total, {0:d} feature annotations (markups) were made.'.format(\n",
    "    total_features_annotations))\n",
    "print(('The average number of features annotated per image by the experts varied per ' +\n",
    "    'diagnosis, from {0:.2f} (SD={1:.2f}) for nevi up to {2:.2f} (SD={3:.2f}) for melanoma').format(\n",
    "    nf_mean_std[0], nf_mean_std[1], mf_mean_std[0], mf_mean_std[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some additional computations for complex statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each image, test whether all five raters agreed on one feature\n",
    "feature_annotations = dict()\n",
    "feature_annotation_stats = dict()\n",
    "user_feature_stats = [[[] for n in range(len(study.images))]\n",
    "    for u in range(len(user_idx))]\n",
    "for feature in full_features_list:\n",
    "    feature_annotations[feature] = dict()\n",
    "    feature_annotation_stats[feature] = None\n",
    "image_agreed = [False] * len(study.images)\n",
    "image_agreed_features = [[] for l in range(len(study.images))]\n",
    "image_orphan_features = []\n",
    "for (idx, image) in enumerate(study.images):\n",
    "    image_id = image['_id']\n",
    "    image_name = image['name']\n",
    "    study.select_annotations(images=[image_id], users=users)\n",
    "    ao = [a for a in study.annotation_selection.values()]\n",
    "    for feature in ao[0].features.keys():\n",
    "        agreed = [False] * len(ao)\n",
    "        for (aidx, a) in enumerate(ao):\n",
    "            if feature in a.features:\n",
    "                agreed[aidx] = True\n",
    "                break\n",
    "        if all(agreed):\n",
    "            image_agreed[idx] = True\n",
    "            image_agreed_features[idx].append(feature)\n",
    "    for a in ao:\n",
    "        uidx = user_idx[a.user_id]\n",
    "        for (feature,fc) in a.features.items():\n",
    "            user_feature_stats[uidx][idx].append(\n",
    "                '{0:d} ({1:d})'.format(features_idx[feature], len(fc['idx'])))\n",
    "            if not feature in feature_annotations:\n",
    "                feature_annotations[feature] = dict()\n",
    "            if not image_name in feature_annotations[feature]:\n",
    "                feature_annotations[feature][image_name] = 0\n",
    "            feature_annotations[feature][image_name] += 1\n",
    "for feature in full_features_list:\n",
    "    features_annotated = [1 if v >= 3 else 0\n",
    "        for v in feature_annotations[feature].values()]\n",
    "    if not features_annotated:\n",
    "        continue\n",
    "    feature_agreed = sum(features_annotated)\n",
    "    feature_annotation_stats[feature] = feature_agreed / len(\n",
    "        feature_annotations[feature])\n",
    "feature_annotation_levels = numpy.asarray(\n",
    "    [v for v in feature_annotation_stats.values() if not v is None])\n",
    "if print_details:\n",
    "    print('Feature-in-image agreements:')\n",
    "total_agreements = 0\n",
    "for (image, a, af) in zip(study.images, image_agreed, image_agreed_features):\n",
    "    if a:\n",
    "        total_agreements += len(af)\n",
    "        image_name = image['name']\n",
    "print('There were a total of {0:d} feature-in-image agreements.'.format(\n",
    "    total_agreements))\n",
    "print(('These were reached in a total of {0:d} images.').format(\n",
    "    numpy.sum(image_agreed)))\n",
    "gold_standard_50 = [feature for (feature, a_level) in feature_annotation_stats.items()\n",
    "    if a_level and a_level >= 0.5]\n",
    "print('The gold standard (of 60% agreement) was reached for ' +\n",
    "    '{0:d}'.format(len(gold_standard_50)) + ' features:')\n",
    "for feature in gold_standard_50:\n",
    "    print(' - {0:.1f}% cases for feature \"{1:s}\"'.format(\n",
    "        100.0 * feature_annotation_stats[feature], feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# count features, including orphans\n",
    "feature_markups = dict()\n",
    "feature_in_images = dict()\n",
    "agreed_2 = dict()\n",
    "agreed_3 = dict()\n",
    "agreed_4 = dict()\n",
    "agreed_5 = dict()\n",
    "exem_missed = dict()\n",
    "exem_orphan = dict()\n",
    "exem_agreed_2 = dict()\n",
    "exem_agreed_3 = dict()\n",
    "exem_agreed_4 = dict()\n",
    "exem_agreed_5 = dict()\n",
    "for feat_name in features_list:\n",
    "    feature_markups[feat_name] = 0\n",
    "    feature_in_images[feat_name] = set()\n",
    "    agreed_2[feat_name] = []\n",
    "    agreed_3[feat_name] = []\n",
    "    agreed_4[feat_name] = []\n",
    "    agreed_5[feat_name] = []\n",
    "    exem_missed[feat_name] = []\n",
    "    exem_orphan[feat_name] = []\n",
    "    exem_agreed_2[feat_name] = []\n",
    "    exem_agreed_3[feat_name] = []\n",
    "    exem_agreed_4[feat_name] = []\n",
    "    exem_agreed_5[feat_name] = []\n",
    "orphans = 0\n",
    "orphan_image_features = []\n",
    "orphan_features = dict()\n",
    "benign_diag_images = []\n",
    "benign_diag_features = dict()\n",
    "malignant_diag_images = []\n",
    "malignant_diag_features = dict()\n",
    "unclear_diag_images = []\n",
    "unclear_diag_features = dict()\n",
    "user_diagnosis = {u: [] for u in users}\n",
    "for (idx, image) in enumerate(study.images):\n",
    "    image_id = image['_id']\n",
    "    image_name = image['name']\n",
    "    study.select_annotations(images=[image_id], users=users)\n",
    "    ao = [a for a in study.annotation_selection.values()]\n",
    "    diag_benign = False\n",
    "    diag_malignant = False\n",
    "    diag_unclear = False\n",
    "    diag_unknown = False\n",
    "    user_diag = {a.user_id: False for a in ao}\n",
    "    for a in ao:\n",
    "        try:\n",
    "            image_diag = a.responses['Classify the Lesion as Benign or Malignant']\n",
    "            user_diagnosis[a.user_id].append(image_diag)\n",
    "            if image_diag[0] == 'B':\n",
    "                diag_benign = True\n",
    "            elif image_diag[0] == 'M':\n",
    "                diag_malignant = True\n",
    "        except:\n",
    "            user_diagnosis[a.user_id].append('Unsure')\n",
    "            diag_unknown = True\n",
    "            pass\n",
    "    for (u, u_d) in user_diag.items():\n",
    "        if not u_d:\n",
    "            user_diagnosis[u].append(None)\n",
    "    if diag_benign and diag_malignant:\n",
    "        diag_unclear = True\n",
    "        unclear_diag_images.append(image_id)\n",
    "    elif diag_benign and not diag_unknown:\n",
    "        benign_diag_images.append(image_id)\n",
    "    elif diag_malignant and not diag_unknown:\n",
    "        malignant_diag_images.append(image_id)\n",
    "    ecount = 0\n",
    "    efeature = study.meta_data['exemplar'][image_name]\n",
    "    for feature in features_list:\n",
    "        fcount = 0\n",
    "        for a in ao:\n",
    "            if feature in a.features:\n",
    "                fcount += 1\n",
    "                if feature == efeature:\n",
    "                    ecount += 1\n",
    "                if diag_unclear:\n",
    "                    if not feature in unclear_diag_features:\n",
    "                        unclear_diag_features[feature] = []\n",
    "                    unclear_diag_features[feature].append(image_id)\n",
    "                elif diag_benign and not diag_unknown:\n",
    "                    if not feature in benign_diag_features:\n",
    "                        benign_diag_features[feature] = []\n",
    "                    benign_diag_features[feature].append(image_id)\n",
    "                elif diag_malignant and not diag_unknown:\n",
    "                    if not feature in malignant_diag_features:\n",
    "                        malignant_diag_features[feature] = []\n",
    "                    malignant_diag_features[feature].append(image_id)\n",
    "        if fcount > 1:\n",
    "            agreed_2[feature].append(image_name)\n",
    "        if fcount > 2:\n",
    "            agreed_3[feature].append(image_name)\n",
    "        if fcount > 3:\n",
    "            agreed_4[feature].append(image_name)\n",
    "        if fcount > 4:\n",
    "            agreed_5[feature].append(image_name)\n",
    "    if ecount == 0:\n",
    "        exem_missed[efeature].append(image_name)\n",
    "    elif ecount == 1:\n",
    "        exem_orphan[efeature].append(image_name)\n",
    "    elif ecount == 2:\n",
    "        exem_agreed_2[efeature].append(image_name)\n",
    "    elif ecount == 3:\n",
    "        exem_agreed_3[efeature].append(image_name)\n",
    "    elif ecount == 4:\n",
    "        exem_agreed_4[efeature].append(image_name)\n",
    "    elif ecount == 5:\n",
    "        exem_agreed_5[efeature].append(image_name)\n",
    "    for (aidx, a) in enumerate(ao):\n",
    "        for feature in a.features:\n",
    "            feature_markups[feature] += 1\n",
    "            feature_in_images[feature].add(image_name)\n",
    "            is_orphan = True\n",
    "            for (aidx2, a2) in enumerate(ao):\n",
    "                if aidx == aidx2:\n",
    "                    continue\n",
    "                for feature2 in a2.features:\n",
    "                    if feature2 == feature:\n",
    "                        is_orphan = False\n",
    "                        break\n",
    "                if not is_orphan:\n",
    "                    break\n",
    "            if is_orphan:\n",
    "                orphans += 1\n",
    "                orphan_image_features.append(feature + ' in ' + \n",
    "                    image_name + ' by ' + a.user['name'])\n",
    "                if not feature in orphan_features:\n",
    "                    orphan_features[feature] = 0\n",
    "                orphan_features[feature] += 1\n",
    "print('An orphan observation of a feature occurred {0:d} times.'.format(\n",
    "    orphans))\n",
    "if print_details:\n",
    "    print('{0:d} orphan features were selected:'.format(orphans))\n",
    "    for orphaned in orphan_image_features:\n",
    "        print(' - ' + orphaned)\n",
    "    print('Presenting by list of features:')\n",
    "    for feature in sorted(orphan_features.keys()):\n",
    "        print(' - {0:-2d} times \"{1:s}\"'.format(\n",
    "            orphan_features[feature], feature))\n",
    "    print('')\n",
    "print('Out of the {0:d} images, {1:d} were given mixed diagnoses.'.format(\n",
    "    len(study.images), len(unclear_diag_images)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# how many exemplar feature annotations for each image with an exemplar?\n",
    "gold_standard_examplars = 0\n",
    "total_exemplar_images = 0\n",
    "total_found_direct = 0\n",
    "total_found_list = []\n",
    "total_found_category = 0\n",
    "total_found_specific = 0\n",
    "for exemplar in sorted(exem_images.keys()):\n",
    "    images = exem_images[exemplar]\n",
    "    if print_details:\n",
    "        print('Exemplar \"{0:s}\" with {1:d} images:'.format(\n",
    "            exemplar, len(images)))\n",
    "    for image in images:\n",
    "        total_exemplar_images += 1\n",
    "        study.select_annotations(images=[image], users=users)\n",
    "        ao = [a for a in study.annotation_selection.values()]\n",
    "        found_direct = 0\n",
    "        found_category = 0\n",
    "        found_specific = 0\n",
    "        for (idx,a) in enumerate(ao):\n",
    "            if exemplar in a.features:\n",
    "                found_direct += 1\n",
    "                found_category += 1\n",
    "                found_specific +=1\n",
    "                continue\n",
    "            found_at_all = False\n",
    "            for feature in a.features:\n",
    "                feature = feature.split(' : ')\n",
    "                if exemplar[0:len(feature[0])] == feature[0]:\n",
    "                    found_category += 1\n",
    "                    found_at_all = True\n",
    "                if feature[-1] in exemplar:\n",
    "                    found_specific += 1\n",
    "                    found_at_all = True\n",
    "                if found_at_all:\n",
    "                    break\n",
    "        if found_direct >= 3:\n",
    "            gold_standard_examplars += 1\n",
    "        if found_direct == len(ao):\n",
    "            total_found_direct += 1\n",
    "            total_found_list.append(image)\n",
    "        if found_specific == len(ao):\n",
    "            total_found_specific += 1\n",
    "        if found_category == len(ao):\n",
    "            total_found_category += 1\n",
    "        if print_details:\n",
    "            print((' - {0:s} has {1:d} annotations; ' +\n",
    "                   '{2:d}, {3:d}, and {4:d} with the full, category, ' +\n",
    "                   'and specific exemplar').format(image,\n",
    "                    len(ao), found_direct, found_category, found_specific))\n",
    "print(('Out of {0:d} images with an exemplar, the gold standard for the\\n' +\n",
    "    'exemplar image (60% agreement) was reached {1:d} times (~{2:d}%).').format(\n",
    "    total_exemplar_images, gold_standard_examplars,\n",
    "    int(100*gold_standard_examplars/total_exemplar_images)))\n",
    "print('And out of these same images, all readers identified this')\n",
    "print('feature {0:d} times, with {1:d} category and {2:d} specific hits.'.format(\n",
    "    total_found_direct, total_found_category, total_found_specific))\n",
    "if print_details:\n",
    "    print('Direct hits:')\n",
    "    for image in total_found_list:\n",
    "        print(' - {0:s} ({1:s})'.format(image,\n",
    "            study.meta_data['exemplar'][image]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# compute the superpixel-wise agreement\n",
    "# (i.e. where 2 or more readers all agreed or any reader\n",
    "# disagreed with the feature in the same superpixel)\n",
    "print_fine_details=False\n",
    "if print_details:\n",
    "    print('Per-image super-pixel agreement:')\n",
    "image_sp_stats = dict()\n",
    "gs_agreed = 0\n",
    "total_agreed = 0\n",
    "total_disagreed = 0\n",
    "sp_agreed_features = dict()\n",
    "for (image_name, image_stats) in study_stats.items():\n",
    "    orphans = 0\n",
    "    agreed = 0\n",
    "    disagreed = 0\n",
    "    for (spidx, sp_stats) in image_stats['sp'].items():\n",
    "        sp_keys = list(sp_stats.keys())\n",
    "        for sp_key in sp_keys:\n",
    "            if not sp_key in sp_agreed_features:\n",
    "                sp_agreed_features[sp_key] = {\n",
    "                    'agreed': 0,\n",
    "                    'disagreed': 0,\n",
    "                    'full_agreed': 0,\n",
    "                    'full_agreed_plus': 0,\n",
    "                    'gs_agreed': 0,\n",
    "                    'number': 0,\n",
    "                    'overlap': dict(),\n",
    "                }\n",
    "        if len(sp_keys) == 1:\n",
    "            sp_agreed_features[sp_keys[0]]['number'] += 1\n",
    "            if len(sp_stats[sp_keys[0]]) == 1:\n",
    "                orphans += 1\n",
    "            else:\n",
    "                agreed += 1\n",
    "                sp_agreed_features[sp_keys[0]]['agreed'] += 1\n",
    "                if len(sp_stats[sp_keys[0]]) > 2:\n",
    "                    sp_agreed_features[sp_key]['gs_agreed'] += 1\n",
    "                    if len(sp_stats[sp_keys[0]]) > 4:\n",
    "                        sp_agreed_features[sp_key]['full_agreed'] += 1\n",
    "                        sp_agreed_features[sp_key]['full_agreed_plus'] += 1\n",
    "        else:\n",
    "            disagreed += 1\n",
    "            for sp_key in sp_keys:\n",
    "                sp_agreed_features[sp_key]['number'] += 1\n",
    "                sp_agreed_features[sp_key]['disagreed'] += 1\n",
    "                if len(sp_stats[sp_key]) >= 3:\n",
    "                    sp_agreed_features[sp_key]['gs_agreed'] += 1\n",
    "                    if len(sp_stats[sp_key]) > 4:\n",
    "                        sp_agreed_features[sp_key]['full_agreed_plus'] += 1\n",
    "                for o_key in sp_keys:\n",
    "                    if sp_key != o_key:\n",
    "                        if not o_key in sp_agreed_features[sp_key]['overlap']:\n",
    "                            sp_agreed_features[sp_key]['overlap'][o_key] = 0\n",
    "                        sp_agreed_features[sp_key]['overlap'][o_key] += 1\n",
    "    total_agreed += agreed\n",
    "    total_disagreed += disagreed\n",
    "    image_sp_stats[image_name] = {\n",
    "        'orphans': orphans, 'agreed': agreed, 'disagreed': disagreed}\n",
    "    if print_details:\n",
    "        try:\n",
    "            print(' - {0:s} {1:-4.1f}% agreed ({2:d} SPs, w/o orphans)'.format(\n",
    "                image_name, 100.0 * float(agreed) / float(agreed + disagreed),\n",
    "                agreed + disagreed))\n",
    "        except:\n",
    "            pass\n",
    "print('Total agreement {0:-4.1f}% ({1:d} out of {2:d} total superpixels)'.format(\n",
    "    100.0 * float(total_agreed) / float(total_agreed + total_disagreed),\n",
    "    total_agreed, total_agreed + total_disagreed))\n",
    "if print_details:\n",
    "    print('Agreement by feature:')\n",
    "    for sp_key in sorted(sp_agreed_features.keys()):\n",
    "        try:\n",
    "            sp_agreement = sp_agreed_features[sp_key]\n",
    "            print(' - {0:-5.2f}% GS / {1:-5.2f}% full ({2:-5.2f}% non dis-agreement for {3:s} ({4:d} SPs)'.format(\n",
    "                100.0 * float(sp_agreement['gs_agreed']) / float(sp_agreement['number']),\n",
    "                100.0 * float(sp_agreement['full_agreed_plus']) / float(sp_agreement['number']),\n",
    "                100.0 * float(sp_agreement['agreed']) / float(sp_agreement['number']),\n",
    "                sp_key, sp_agreement['number']))\n",
    "            if print_fine_details:\n",
    "                for o_key in sorted(sp_agreement['overlap'].keys()):\n",
    "                    print('   - {0:-3d} overlapped with {1:s}'.format(\n",
    "                        sp_agreement['overlap'][o_key], o_key))\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the superpixel-wise agreement\n",
    "# (i.e. where 2 or more readers all agreed or any reader\n",
    "# disagreed with the feature in the same superpixel)\n",
    "exemplar_sp_stats = {\n",
    "    'image': [],\n",
    "    'feature': [],\n",
    "    'pwdmed': [],\n",
    "    'totalrs': [],\n",
    "    'totalsp': [],\n",
    "    '1r': [],\n",
    "    '2r': [],\n",
    "    '3r': [],\n",
    "    '4r': [],\n",
    "    '5r': [],\n",
    "}\n",
    "exemplar_features = study.meta_data['exemplar']\n",
    "for (idx, image) in enumerate(study.images):\n",
    "    image_id = image['_id']\n",
    "    image_name = image['name']\n",
    "    f = exemplar_features[image_name]\n",
    "    study.select_annotations(images=[image_id], users=users, features=[f])\n",
    "    ao = [a for a in study.annotation_selection.values()]\n",
    "    sps = dict()\n",
    "    pdice = []\n",
    "    for (idx, a1) in enumerate(ao):\n",
    "        spidx = a1.features[f]['idx']\n",
    "        for si in spidx:\n",
    "            if not si in sps:\n",
    "                sps[si] = 1\n",
    "            else:\n",
    "                sps[si] += 1\n",
    "        for (idx2, a2) in enumerate(ao):\n",
    "            if idx2 == idx:\n",
    "                continue\n",
    "            spidx2 = a2.features[f]['idx']\n",
    "            spii = numpy.intersect1d(spidx, spidx2)\n",
    "            pdice.append(2.0 * float(len(spii)) / float(len(spidx) + len(spidx2)))\n",
    "    spn = [0, 0, 0, 0, 0, 0, 0]\n",
    "    for siv in sps.values():\n",
    "        spn[siv] += 1\n",
    "    exemplar_sp_stats['image'].append(image_name)\n",
    "    exemplar_sp_stats['feature'].append(f)\n",
    "    if len(pdice) > 0:\n",
    "        exemplar_sp_stats['pwdmed'].append(float(numpy.median(pdice)))\n",
    "    else:\n",
    "        exemplar_sp_stats['pwdmed'].append(float(numpy.nan))\n",
    "    exemplar_sp_stats['totalrs'].append(len(ao))\n",
    "    exemplar_sp_stats['totalsp'].append(len(sps))\n",
    "    exemplar_sp_stats['1r'].append(spn[1])\n",
    "    exemplar_sp_stats['2r'].append(spn[2])\n",
    "    exemplar_sp_stats['3r'].append(spn[3])\n",
    "    exemplar_sp_stats['4r'].append(spn[4])\n",
    "    exemplar_sp_stats['5r'].append(spn[5])\n",
    "    if spn[6] > 0:\n",
    "        print(image_name)\n",
    "api.write_csv(study_folder + 'EASY_Study' + study_part + '_exemplar_sp_stats.csv', exemplar_sp_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute feature-based super-pixel co-occurrences\n",
    "benign_features = dict()\n",
    "malignant_features = dict()\n",
    "category_sp_hits = numpy.zeros((num_categories, num_categories,))\n",
    "category_sp_miss = numpy.zeros((num_categories, num_categories,))\n",
    "category_sp_basis = numpy.zeros((num_categories, num_categories,))\n",
    "feature_sp_hits = numpy.zeros((num_features, num_features,))\n",
    "feature_sp_miss = numpy.zeros((num_features, num_features,))\n",
    "feature_sp_basis = numpy.zeros((num_features, num_features,))\n",
    "feat_cat_sp_hits = numpy.zeros((num_features, num_categories,))\n",
    "feat_cat_sp_miss = numpy.zeros((num_features, num_categories,))\n",
    "feat_cat_sp_basis = numpy.zeros((num_features, num_categories,))\n",
    "sp_pairs_overlap = dict()\n",
    "sp_pairs_overlap_diag = dict()\n",
    "sp_thresh_min = 2.0 / 3.0\n",
    "sp_thresh_max = 3.0 / 2.0\n",
    "for (idx, image) in enumerate(study.images):\n",
    "    image_id = image['_id']\n",
    "    study.select_annotations(images=[image_id], users=users)\n",
    "    ao = [a for a in study.annotation_selection.values()]\n",
    "    for (aidx, a) in enumerate(ao):\n",
    "        for (feature, fcont) in a.features.items():\n",
    "            feature_cat = feature.split(' : ')[0]\n",
    "            try:\n",
    "                feature_diag = (a.responses['Classify the Lesion as Benign or Malignant']\n",
    "                    + '>' + feature)\n",
    "                if feature_diag[0] == 'B':\n",
    "                    if not feature in benign_features:\n",
    "                        benign_features[feature] = []\n",
    "                    benign_features[feature].append(image_id)\n",
    "                elif feature_diag[0] == 'M':\n",
    "                    if not feature in malignant_features:\n",
    "                        malignant_features[feature] = []\n",
    "                    malignant_features[feature].append(image_id)\n",
    "            except:\n",
    "                feature_diag = 'Unsure>' + feature\n",
    "            fnum = features_idx[feature]\n",
    "            cnum = category_idx[feature_cat]\n",
    "            fidx = set(fcont['idx'])\n",
    "            didx = float(len(fidx))\n",
    "            for (aidx2, a2) in enumerate(ao):\n",
    "                if aidx == aidx2:\n",
    "                    continue\n",
    "                for (feature2, fcont2) in a2.features.items():\n",
    "                    feature2_cat = feature2.split(' : ')[0]\n",
    "                    try:\n",
    "                        feature2_diag = (a2.responses['Benign or Malignant']\n",
    "                            + '>' + feature2)\n",
    "                    except:\n",
    "                        feature2_diag = 'Unsure>' + feature2\n",
    "                    fnum2 = features_idx[feature2]\n",
    "                    cnum2 = category_idx[feature2_cat]\n",
    "                    fidx2 = set(fcont2['idx'])\n",
    "                    didx2 = float(len(fidx2))\n",
    "                    finter = fidx.intersection(fidx2)\n",
    "                    finterlen = float(len(finter))\n",
    "                    category_sp_hits[cnum,cnum2] += finterlen\n",
    "                    category_sp_hits[cnum2,cnum] += finterlen\n",
    "                    category_sp_miss[cnum,cnum2] += didx - finterlen\n",
    "                    category_sp_miss[cnum2,cnum] += didx2 - finterlen\n",
    "                    category_sp_basis[cnum,cnum2] += didx\n",
    "                    category_sp_basis[cnum2,cnum] += didx2\n",
    "                    feature_sp_hits[fnum,fnum2] += finterlen\n",
    "                    feature_sp_hits[fnum2,fnum] += finterlen\n",
    "                    feature_sp_miss[fnum,fnum2] += didx - finterlen\n",
    "                    feature_sp_miss[fnum2,fnum] += didx2 - finterlen\n",
    "                    feature_sp_basis[fnum,fnum2] += didx\n",
    "                    feature_sp_basis[fnum2,fnum] += didx2\n",
    "                    feat_cat_sp_hits[fnum,cnum2] += finterlen\n",
    "                    feat_cat_sp_hits[fnum2,cnum] += finterlen\n",
    "                    feat_cat_sp_miss[fnum,cnum2] += didx - finterlen\n",
    "                    feat_cat_sp_miss[fnum2,cnum] += didx2 - finterlen\n",
    "                    feat_cat_sp_basis[fnum,cnum2] += didx\n",
    "                    feat_cat_sp_basis[fnum2,cnum] += didx2\n",
    "                    if aidx >= aidx2 or feature == feature2:\n",
    "                        continue\n",
    "                    if didx < 3 or didx2 < 3:\n",
    "                        continue\n",
    "                    dfac = didx / didx2\n",
    "                    if dfac < sp_thresh_min or dfac > sp_thresh_max:\n",
    "                        continue\n",
    "                    if feature < feature2:\n",
    "                        fp = feature + ' *and* ' + feature2\n",
    "                    else:\n",
    "                        fp = feature2 + ' *and* ' + feature\n",
    "                    fp_dice = 2 * finterlen / (didx + didx2)\n",
    "                    if not fp in sp_pairs_overlap:\n",
    "                        sp_pairs_overlap[fp] = []\n",
    "                    sp_pairs_overlap[fp].append(fp_dice)\n",
    "                    if feature_diag < feature2_diag:\n",
    "                        fp = feature_diag + ' *and* ' + feature2_diag\n",
    "                    else:\n",
    "                        fp = feature2_diag + ' *and* ' + feature_diag\n",
    "                    if not fp in sp_pairs_overlap_diag:\n",
    "                        sp_pairs_overlap_diag[fp] = []\n",
    "                    sp_pairs_overlap_diag[fp].append(fp_dice)\n",
    "category_sp_basis[category_sp_basis == 0.0] = 1.0\n",
    "category_sp_hits = category_sp_hits / category_sp_basis\n",
    "category_sp_miss = category_sp_miss / category_sp_basis\n",
    "feature_sp_basis[feature_sp_basis == 0.0] = 1.0\n",
    "feature_sp_hits = feature_sp_hits / feature_sp_basis\n",
    "feature_sp_miss = feature_sp_miss / feature_sp_basis\n",
    "feat_cat_sp_basis[feat_cat_sp_basis == 0.0] = 1.0\n",
    "feat_cat_sp_hits = feat_cat_sp_hits / feat_cat_sp_basis\n",
    "feat_cat_sp_miss = feat_cat_sp_miss / feat_cat_sp_basis\n",
    "sp_pairs_overlap_diagsame = {\n",
    "    fp: fp_list for (fp, fp_list) in sp_pairs_overlap_diag.items()}\n",
    "for fp in list(sp_pairs_overlap.keys()):\n",
    "    if len(sp_pairs_overlap[fp]) < sp_minpairs:\n",
    "        sp_pairs_overlap.pop(fp)\n",
    "for fp in list(sp_pairs_overlap_diag.keys()):\n",
    "    if (len(sp_pairs_overlap_diag[fp]) < sp_diag_minpairs or\n",
    "        not 'Benign' in fp or not 'Malignant' in fp):\n",
    "        sp_pairs_overlap_diag.pop(fp)\n",
    "for fp in list(sp_pairs_overlap_diagsame.keys()):\n",
    "    if (len(sp_pairs_overlap_diagsame[fp]) < sp_diag_minpairs or\n",
    "        'Unsure' in fp or\n",
    "        ('Benign' in fp and 'Malignant' in fp)):\n",
    "        sp_pairs_overlap_diagsame.pop(fp)\n",
    "sp_pairs_overlap = list(reversed(sorted(sp_pairs_overlap.items(),\n",
    "    key=lambda x: numpy.mean(x[1]))))\n",
    "sp_pairs_overlap_diag = list(reversed(sorted(sp_pairs_overlap_diag.items(),\n",
    "    key=lambda x: numpy.mean(x[1]))))\n",
    "sp_pairs_overlap_diagsame = list(reversed(sorted(sp_pairs_overlap_diagsame.items(),\n",
    "    key=lambda x: numpy.mean(x[1]))))\n",
    "sp_pairs_highoverlap = sum(\n",
    "    [1 if numpy.mean(sp[1]) >= sp_list_thresh else 0 for sp in sp_pairs_overlap])\n",
    "sp_pairs_highoverlap_diag = sum(\n",
    "    [1 if numpy.mean(sp[1]) >= sp_list_thresh else 0 for sp in sp_pairs_overlap_diag])\n",
    "sp_pairs_highoverlap_diagsame = sum(\n",
    "    [1 if numpy.mean(sp[1]) >= sp_list_thresh else 0\n",
    "     for sp in sp_pairs_overlap_diagsame])\n",
    "print(('There are {0:d} pairs of discordant features with ' +\n",
    "    'high (> {1:.2f} DICE) overlap:').format(sp_pairs_highoverlap, sp_list_thresh))\n",
    "if print_details:\n",
    "    for sp in sp_pairs_overlap:\n",
    "        sp_mean = numpy.mean(sp[1])\n",
    "        if sp_mean < sp_list_thresh:\n",
    "            break\n",
    "        print(' - {0:.1f}% ({1:d} pairs) for features {2:s}'.format(\n",
    "            100.0 * sp_mean, len(sp[1]), sp[0]))\n",
    "    print('')\n",
    "disdiag_sp_overlap = []\n",
    "for (feature, feature_images) in benign_features.items():\n",
    "    if feature in malignant_features:\n",
    "        continue\n",
    "    for image_id in feature_images:\n",
    "        for (feature2, feature2_images) in malignant_features.items():\n",
    "            if not image_id in feature2_images:\n",
    "                continue\n",
    "            study.select_annotations(images=[image_id], users=users,\n",
    "                features=[feature, feature2])\n",
    "            ao = [a for a in study.annotation_selection.values()]\n",
    "            for (aidx, a) in enumerate(ao):\n",
    "                if not feature in a.features:\n",
    "                    continue\n",
    "                fcont = a.features[feature]\n",
    "                fidx = set(fcont['idx'])\n",
    "                didx = float(len(fidx))\n",
    "                for (aidx2, a2) in enumerate(ao):\n",
    "                    if aidx == aidx2:\n",
    "                        continue\n",
    "                    if not feature2 in a2.features:\n",
    "                        continue\n",
    "                    fcont2 = a2.features[feature2]\n",
    "                    fidx2 = set(fcont2['idx'])\n",
    "                    didx2 = float(len(fidx2))\n",
    "                    finter = fidx.intersection(fidx2)\n",
    "                    finterlen = float(len(finter))\n",
    "                    fp_dice = 2 * finterlen / (didx + didx2)\n",
    "                    if fp_dice < sp_list_thresh:\n",
    "                        continue\n",
    "                    disdiag_sp_overlap.append({\n",
    "                        'Image': a.image['name'],\n",
    "                        'Reader1': user_names[a.user_id],\n",
    "                        'Reader2': user_names[a2.user_id],\n",
    "                        'Benign': feature,\n",
    "                        'Malignant': feature2,\n",
    "                        'DICE': fp_dice,\n",
    "                    })\n",
    "for (feature, feature_images) in malignant_features.items():\n",
    "    if feature in benign_features:\n",
    "        continue\n",
    "    for image_id in feature_images:\n",
    "        for (feature2, feature2_images) in benign_features.items():\n",
    "            if not image_id in feature2_images:\n",
    "                continue\n",
    "            study.select_annotations(images=[image_id], users=users,\n",
    "                features=[feature, feature2])\n",
    "            ao = [a for a in study.annotation_selection.values()]\n",
    "            for (aidx, a) in enumerate(ao):\n",
    "                if not feature in a.features:\n",
    "                    continue\n",
    "                fcont = a.features[feature]\n",
    "                fidx = set(fcont['idx'])\n",
    "                didx = float(len(fidx))\n",
    "                for (aidx2, a2) in enumerate(ao):\n",
    "                    if aidx == aidx2:\n",
    "                        continue\n",
    "                    if not feature2 in a2.features:\n",
    "                        continue\n",
    "                    fcont2 = a2.features[feature2]\n",
    "                    fidx2 = set(fcont2['idx'])\n",
    "                    didx2 = float(len(fidx2))\n",
    "                    finter = fidx.intersection(fidx2)\n",
    "                    finterlen = float(len(finter))\n",
    "                    fp_dice = 2 * finterlen / (didx + didx2)\n",
    "                    if fp_dice < sp_list_thresh:\n",
    "                        continue\n",
    "                    disdiag_sp_overlap.append({\n",
    "                        'Image': a.image['name'],\n",
    "                        'Reader1': user_names[a2.user_id],\n",
    "                        'Reader2': user_names[a.user_id],\n",
    "                        'Benign': feature2,\n",
    "                        'Malignant': feature,\n",
    "                        'DICE': fp_dice,\n",
    "                    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Superpixel explanation (image)\n",
    "\n",
    "Superpixels are an automatic segmentation performed by the ISIC Archive,\n",
    "which then allows annotators (readers) to select specific parcels of an\n",
    "image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a heatmap with default settings (Study 4, User: Liopyris)\n",
    "sample_image = api.image('ISIC_0016094')\n",
    "sample_image.load_image_data()\n",
    "sample_data = sample_image.data\n",
    "sample_image.mark_superpixels()\n",
    "sp_data = sample_image.data\n",
    "sample_image.clear_data()\n",
    "(heatmap, stats) = study.image_heatmap('ISIC_0016094',\n",
    "    mix_colors=False,underlay_gray=0.8,users=['578e64b09fc3c10d6fd12e4f'])\n",
    "sp_image = imfunc.image_mix(sp_data, heatmap)\n",
    "sp_comparison = numpy.concatenate((sample_data, sp_image), axis=1)\n",
    "api.write_image(sp_comparison, study_folder + 'ISIC_0016094+hm_w_sp.png')\n",
    "api.show_image_in_notebook(sp_comparison, max_size=1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heatmaps\n",
    "\n",
    "The images below show (1) a demonstration of people using\n",
    "different terms for the same feature, (2) people agreeing\n",
    "agreeing on one specific term (but not others), and (3)\n",
    "everybody agreeing on the (singular) term in an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show three images (heatmaps) of the study with agreement examples\n",
    "print('(1)')\n",
    "(heatmap, heatmap_stats) = study.image_heatmap('ISIC_0016080',\n",
    "    users=users, underlay_gray=heatmap_underlay_gray,\n",
    "    mix_colors=heatmap_mix_colors, resize_output=4096)\n",
    "api.show_image_in_notebook(heatmap, max_size=1024)\n",
    "print('(2)')\n",
    "(heatmap, heatmap_stats) = study.image_heatmap('ISIC_0016094',\n",
    "    users=users, underlay_gray=heatmap_underlay_gray,\n",
    "    mix_colors=heatmap_mix_colors, resize_output=4096)\n",
    "api.show_image_in_notebook(heatmap, max_size=1024)\n",
    "print('(3)')\n",
    "(heatmap, heatmap_stats) = study.image_heatmap('ISIC_0016128',\n",
    "    users=users, underlay_gray=heatmap_underlay_gray,\n",
    "    mix_colors=heatmap_mix_colors, resize_output=4096)\n",
    "api.show_image_in_notebook(heatmap, max_size=1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature overlap/confusion figure\n",
    "\n",
    "The image prepared with the code below shows the matrix of feature overlap,\n",
    "and thus confusability; collapsed across images/diagnoses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# get the color lookup map\n",
    "color_norm = mpl.colors.Normalize(vmin=0.0, vmax=1.0)\n",
    "color_map = cm.ScalarMappable(norm=color_norm, cmap=overlap_colormap)\n",
    "\n",
    "overlap_stats = numpy.load(overlap_stats_file)\n",
    "overlap_features_dice = overlap_stats.get('overlap_features_dice')\n",
    "overlap_feat_cat_dice = overlap_stats.get('overlap_feat_cat_dice')\n",
    "overlap_category_dice = overlap_stats.get('overlap_category_dice')\n",
    "\n",
    "# process data prior to creating the image\n",
    "white_val = numpy.uint8(255)\n",
    "feature_sp_rgb = numpy.trunc(255.0 *\n",
    "    color_map.to_rgba(feature_sp_hits)[:,:,0:3]).astype(numpy.uint8)\n",
    "feat_cat_sp_rgb = numpy.trunc(255.0 *\n",
    "    color_map.to_rgba(feat_cat_sp_hits)[:,:,0:3]).astype(numpy.uint8)\n",
    "category_sp_rgb = numpy.trunc(255.0 *\n",
    "    color_map.to_rgba(category_sp_hits)[:,:,0:3]).astype(numpy.uint8)\n",
    "overlap_features_null = numpy.isnan(overlap_features_dice)\n",
    "overlap_feat_cat_null = numpy.isnan(overlap_feat_cat_dice)\n",
    "overlap_category_null = numpy.isnan(overlap_category_dice)\n",
    "overlap_features_dice[overlap_features_null] = 0\n",
    "overlap_feat_cat_dice[overlap_feat_cat_null] = 0\n",
    "overlap_category_dice[overlap_category_null] = 0\n",
    "overlap_features_rgb = numpy.trunc(255.0 *\n",
    "    color_map.to_rgba(overlap_features_dice[:,:,0])[:,:,0:3]).astype(numpy.uint8)\n",
    "overlap_features_rgb[numpy.repeat(overlap_features_null[:,:,0:1], 3, axis=2)] = 255\n",
    "overlap_feat_cat_rgb = numpy.trunc(255.0 *\n",
    "    color_map.to_rgba(overlap_feat_cat_dice[:,:,0])[:,:,0:3]).astype(numpy.uint8)\n",
    "overlap_feat_cat_rgb[numpy.repeat(overlap_feat_cat_null[:,:,0:1], 3, axis=2)] = 255\n",
    "overlap_category_rgb = numpy.trunc(255.0 *\n",
    "    color_map.to_rgba(overlap_category_dice[:,:,0])[:,:,0:3]).astype(numpy.uint8)\n",
    "overlap_category_rgb[numpy.repeat(overlap_category_null[:,:,0:1], 3, axis=2)] = 255\n",
    "\n",
    "# add spacers spacers\n",
    "f1v = white_val * numpy.ones((overlap_category_dice.shape[0], 2, 3,),\n",
    "    dtype=numpy.uint8)\n",
    "f2v = white_val * numpy.ones((overlap_features_dice.shape[0], 2, 3,),\n",
    "    dtype=numpy.uint8)\n",
    "blank_space = white_val * numpy.ones(\n",
    "    (overlap_category_dice.shape[0], overlap_features_dice.shape[0], 3,),\n",
    "    dtype=numpy.uint8)\n",
    "hits_top_image = numpy.concatenate(\n",
    "    (category_sp_rgb, f1v, blank_space), axis=1)\n",
    "hits_bottom_image = numpy.concatenate(\n",
    "    (feat_cat_sp_rgb, f2v, feature_sp_rgb), axis=1)\n",
    "dice_top_image = numpy.concatenate(\n",
    "    (overlap_category_rgb, f1v, blank_space), axis=1)\n",
    "dice_bottom_image = numpy.concatenate(\n",
    "    (overlap_feat_cat_rgb, f2v, overlap_features_rgb), axis=1)\n",
    "f1h = white_val * numpy.ones((2, dice_top_image.shape[1], 3,), dtype=numpy.uint8)\n",
    "hits_full_image = numpy.concatenate((hits_top_image, f1h, hits_bottom_image), axis=0)\n",
    "dice_full_image = numpy.concatenate((dice_top_image, f1h, dice_bottom_image), axis=0)\n",
    "\n",
    "# blow up by factor 24 (for text attribution)\n",
    "detail_blow_up = 5 * overlap_blow_up\n",
    "hits_detail_image = numpy.repeat(numpy.repeat(\n",
    "    hits_full_image[0:len(category_list), 0:len(category_list), :],\n",
    "    detail_blow_up, axis=0), detail_blow_up, axis=1)\n",
    "hits_full_image = numpy.repeat(numpy.repeat(hits_full_image, overlap_blow_up, axis=0),\n",
    "    overlap_blow_up, axis=1)\n",
    "dice_detail_image = numpy.repeat(numpy.repeat(\n",
    "    dice_full_image[0:len(category_list), 0:len(category_list), :],\n",
    "    detail_blow_up, axis=0), detail_blow_up, axis=1)\n",
    "dice_full_image = numpy.repeat(numpy.repeat(dice_full_image, overlap_blow_up, axis=0),\n",
    "    overlap_blow_up, axis=1)\n",
    "\n",
    "# determine line positions and paint lines\n",
    "line_pos = []\n",
    "cat_name = category_list[0]\n",
    "for (idx,feature) in enumerate(features_list):\n",
    "    if not cat_name in feature:\n",
    "        line_pos.append(idx)\n",
    "        cat_name = feature.split(' : ')[0]\n",
    "line_offset = overlap_blow_up * (len(category_list) + 2) - 1\n",
    "for lp in line_pos:\n",
    "    line_xy = line_offset + overlap_blow_up * lp\n",
    "    hits_full_image[line_xy:line_xy+2,:,:] = 0\n",
    "    hits_full_image[line_offset:, line_xy:line_xy+2,:] = 0\n",
    "    dice_full_image[line_xy:line_xy+2,:,:] = 0\n",
    "    dice_full_image[line_offset:, line_xy:line_xy+2,:] = 0\n",
    "\n",
    "# create text images\n",
    "category_text = calibri.set_line(category_list, fsize=overlap_blow_up-1)\n",
    "category_text_length = [v for v in map(lambda x: x.shape[1], category_text)]\n",
    "detail_text = calibri.set_line(category_list, fsize=(3*overlap_blow_up))\n",
    "detail_text_length = [v for v in map(lambda x: x.shape[1], detail_text)]\n",
    "detail_max_length = max(detail_text_length)\n",
    "features_text = calibri.set_line(features_list, fsize=overlap_blow_up-1)\n",
    "features_text_length = [v for v in map(lambda x: x.shape[1], features_text)]\n",
    "features_max_length = max(features_text_length)\n",
    "detail_timage_x = detail_max_length + 4 * overlap_blow_up\n",
    "detail_timage = white_val * numpy.ones(\n",
    "    (dice_detail_image.shape[0], detail_timage_x, 3, ), dtype=numpy.uint8)\n",
    "text_image_y = overlap_blow_up * (2 + len(category_text) + len(features_text))\n",
    "text_image_x = features_max_length + 2 * overlap_blow_up\n",
    "text_image = white_val * numpy.ones(\n",
    "    (text_image_y, text_image_x, 3,), dtype=numpy.uint8)\n",
    "for (idx, cat_name) in enumerate(category_list):\n",
    "    line_w = category_text_length[idx]\n",
    "    line_text = white_val - numpy.repeat(\n",
    "        category_text[idx].reshape((overlap_blow_up, line_w, 1,)), 3, axis=2)\n",
    "    line_xy = idx * overlap_blow_up\n",
    "    line_x = overlap_blow_up + (features_max_length - line_w)\n",
    "    text_image[line_xy:line_xy+overlap_blow_up,line_x:line_x+line_w,:] = line_text\n",
    "    line_w = detail_text_length[idx]\n",
    "    line_text = white_val - numpy.repeat(detail_text[idx].reshape(\n",
    "        (detail_text[idx].shape[0], line_w, 1,)), 3, axis=2)\n",
    "    line_xy = (idx * 5 + 1) * overlap_blow_up\n",
    "    line_x = 2 * overlap_blow_up + (detail_max_length - line_w)\n",
    "    detail_timage[line_xy:line_xy+line_text.shape[0],line_x:line_x+line_w,:] = line_text\n",
    "for (idx, feat_name) in enumerate(features_list):\n",
    "    line_w = features_text_length[idx]\n",
    "    line_text = white_val - numpy.repeat(\n",
    "        features_text[idx].reshape((overlap_blow_up, line_w, 1,)), 3, axis=2)\n",
    "    line_xy = (len(category_list) + 2 + idx) * overlap_blow_up\n",
    "    line_x = overlap_blow_up + (features_max_length - line_w)\n",
    "    text_image[line_xy:line_xy+overlap_blow_up, line_x:line_x+line_w,:] = line_text\n",
    "\n",
    "# put everything together\n",
    "hits_detail_image = numpy.concatenate((detail_timage, hits_detail_image), axis=1)\n",
    "dice_detail_image = numpy.concatenate((detail_timage, dice_detail_image), axis=1)\n",
    "hits_full_image = numpy.concatenate(\n",
    "    (hits_full_image, imfunc.image_rotate(text_image, 'left')), axis=0)\n",
    "dice_full_image = numpy.concatenate(\n",
    "    (dice_full_image, imfunc.image_rotate(text_image, 'left')), axis=0)\n",
    "text_filler = white_val * numpy.ones((text_image_x, text_image_x, 3,),\n",
    "    dtype=numpy.uint8)\n",
    "text_image = numpy.concatenate((text_image, text_filler), axis=0)\n",
    "hits_full_image = numpy.concatenate((text_image, hits_full_image), axis=1)\n",
    "dice_full_image = numpy.concatenate((text_image, dice_full_image), axis=1)\n",
    "\n",
    "# write and show image\n",
    "api.write_image(hits_detail_image, study_folder + 'EASY_Study' + study_part + '_sp-hits_confusion_markup_cat.png')\n",
    "api.write_image(dice_detail_image, study_folder + 'EASY_Study' + study_part + '_DICE_confusion_markup_cat.png')\n",
    "api.write_image(hits_full_image, study_folder + 'EASY_Study' + study_part + '_sp-hits_confusion_markup_full.png')\n",
    "api.write_image(dice_full_image, study_folder + 'EASY_Study' + study_part + '_DICE_confusion_markup_full.png')\n",
    "detail_combined = numpy.concatenate((hits_detail_image, dice_detail_image), axis=1)\n",
    "api.show_image_in_notebook(detail_combined, max_size=1024)\n",
    "api.show_image_in_notebook(hits_full_image, max_size=1024)\n",
    "api.show_image_in_notebook(dice_full_image, max_size=1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supplementary data\n",
    "\n",
    "## Table of ISIC images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "S1_dict = {\n",
    "    'ISIC name': image_names,\n",
    "    'ISIC imageId': [img['_id'] for img in study.images],\n",
    "    'exemplar feature': [study.meta_data['exemplar'][img['name']] for img in study.images],\n",
    "}\n",
    "api.write_csv('Supplementary_table1.csv', S1_dict)\n",
    "S1_study_images = pd.DataFrame.from_dict(S1_dict)\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    display(S1_study_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tables of dermoscopic features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S2_dermoscopic_features = pd.DataFrame.from_dict({\n",
    "    'Dermoscopic Feature': full_features_list,\n",
    "    'Total observations': [feature_markups[f] if f in feature_markups else 0\n",
    "        for f in full_features_list],\n",
    "    'In total images': [len(feature_in_images[f]) if f in feature_in_images else 0\n",
    "        for f in full_features_list],\n",
    "    'Orphans': [orphan_features[f] if f in orphan_features else 0\n",
    "        for f in full_features_list],\n",
    "    '2-RA': [len(agreed_2[f]) if f in agreed_2 else 0\n",
    "        for f in full_features_list],\n",
    "    'GS (3-RA)': [len(agreed_3[f]) if f in agreed_3 else 0\n",
    "        for f in full_features_list],\n",
    "    '4-RA': [len(agreed_4[f]) if f in agreed_4 else 0\n",
    "        for f in full_features_list],\n",
    "    '5-RA (FA)': [len(agreed_5[f]) if f in agreed_5 else 0\n",
    "        for f in full_features_list],\n",
    "})\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    display(S2_dermoscopic_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if len(users) >= 5:\n",
    "    S3_dermoscopic_exemplars = pd.DataFrame.from_dict({\n",
    "        'Dermoscopic Exemplars': full_features_list,\n",
    "        'Missed': [len(exem_missed[f]) for f in full_features_list],\n",
    "        'Orphans': [len(exem_orphan[f]) for f in full_features_list],\n",
    "        '2-RA': [len(exem_agreed_2[f]) for f in full_features_list],\n",
    "        'GS (3-RA)': [len(exem_agreed_3[f]) for f in full_features_list],\n",
    "        '4-RA': [len(exem_agreed_4[f]) for f in full_features_list],\n",
    "        '5-RA (FA)': [len(exem_agreed_5[f]) for f in full_features_list],\n",
    "    })\n",
    "else:\n",
    "    S3_dermoscopic_exemplars = pd.DataFrame.from_dict({\n",
    "        'Dermoscopic Exemplars': full_features_list,\n",
    "        'Missed': [len(exem_missed[f]) for f in full_features_list],\n",
    "        'Orphans': [len(exem_orphan[f]) for f in full_features_list],\n",
    "        '2-RA': [len(exem_agreed_2[f]) for f in full_features_list],\n",
    "        'GS (3-RA)': [len(exem_agreed_3[f]) for f in full_features_list],\n",
    "        '4-RA (FA)': [len(exem_agreed_4[f]) for f in full_features_list],\n",
    "    })\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    display(S3_dermoscopic_exemplars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of features marked by each reader (+ #SPs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "S4_features_by_image_and_user = pd.DataFrame.from_dict({\n",
    "    'ISIC name': image_names,\n",
    "    'ISIC imageId': [img['_id'] for img in study.images],\n",
    "})\n",
    "for u in study.users:\n",
    "    if u['_id'] in user_idx:\n",
    "        S4_features_by_image_and_user[u['name'][-4:] + ' features'] = user_feature_stats[user_idx[u['_id']]]\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    display(S4_features_by_image_and_user)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
