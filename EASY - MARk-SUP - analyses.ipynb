{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methods for achieving expert agreement of clinical images: the Medical Annotation and Review of Superpixels (MARk-SUP)\n",
    "## Web-based expert annotation platform piloted for expert annotation and quantitative analysis of dermoscopic features\n",
    "\n",
    "### *Online supplementary Jupyter notebook with analyses*\n",
    "\n",
    "The cells in this notebook can be run in succession, or, as\n",
    "desired, cell-by-cell.\n",
    "\n",
    "**Please note:** the first two cells **MUST** be run in order\n",
    "to establish the necessary variables in the workspace of the\n",
    "python kernel!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "from matplotlib import pyplot\n",
    "%matplotlib inline\n",
    "import imageio\n",
    "import numpy\n",
    "from isicarchive import func\n",
    "from isicarchive.api import IsicApi\n",
    "\n",
    "# function for mean and sample STD\n",
    "def mean_std(a:list, is_sample:bool=True):\n",
    "    ddof = 1 if is_sample else 0\n",
    "    return (numpy.mean(a), numpy.std(a, ddof=ddof))\n",
    "\n",
    "# set to True if you would like (more) details in the print-out\n",
    "print_details = False\n",
    "print_fine_details = False\n",
    "heatmap_mix_colors = False\n",
    "heatmap_underlay_gray = 0.8\n",
    "heatmap_resize_output = 4096\n",
    "heatmap_legend_font_size = 144.0\n",
    "\n",
    "# please change the username accordingly!\n",
    "username = 'weberj3@mskcc.org'\n",
    "\n",
    "# root folder for all ISIC related data\n",
    "doc_folder = 'Z:\\\\10.Imaging Informatics\\\\'\n",
    "\n",
    "# cache folder\n",
    "cache_folder = doc_folder + 'ISIC' + os.sep + 'cache'\n",
    "\n",
    "# show URL requests (for debugging purposes only!)\n",
    "debug = False\n",
    "\n",
    "# instantiate API object\n",
    "api = IsicApi(username, cache_folder=cache_folder, debug=debug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# study folder\n",
    "study_folder = doc_folder + 'EASY' + os.sep + 'PILOT' + os.sep\n",
    "\n",
    "# load study and data\n",
    "study = api.study('ISIC Annotation Study - All Features')\n",
    "study.cache_image_data()\n",
    "study.load_annotations()\n",
    "\n",
    "# load meta data\n",
    "meta_data_url = ('https://raw.githubusercontent.com/neuroelf/' +\n",
    "    'isicarchive/master/data/EASY_pilot_diagnoses.csv')\n",
    "study.load_meta_data(meta_data_url, list_to_dict=True,\n",
    "    dict_key='name', extract_key=['diagnosis', 'exemplar'])\n",
    "\n",
    "# and create a dictionary mapping diagnosis to a list of images\n",
    "diag_images = dict()\n",
    "for (name, diag) in study.meta_data['diagnosis'].items():\n",
    "    if not diag in diag_images:\n",
    "        diag_images[diag] = []\n",
    "    diag_images[diag].append(name)\n",
    "\n",
    "# same for exemplar features\n",
    "exem_images = dict()\n",
    "for (name, exemplar) in study.meta_data['exemplar'].items():\n",
    "    if not exemplar:\n",
    "        continue\n",
    "    if not exemplar in exem_images:\n",
    "        exem_images[exemplar] = []\n",
    "    exem_images[exemplar].append(name)\n",
    "\n",
    "# select only from users that completed the study\n",
    "num_images = len(study.images)\n",
    "users = [u for (u,c) in study.user_completion.items() if c==num_images]\n",
    "\n",
    "# create heatmaps with default settings (if not yet done)\n",
    "study_stats_file = study_folder + 'heatmap_stats.json.gz'\n",
    "if not os.path.exists(study_stats_file):\n",
    "    study_stats = study.image_heatmaps(study_folder, users=users,\n",
    "        mix_colors=heatmap_mix_colors, underlay_gray=heatmap_underlay_gray, \n",
    "        resize_output=heatmap_resize_output, font_size=heatmap_legend_font_size)\n",
    "else:\n",
    "    study_stats = func.gzip_load_var(study_stats_file)\n",
    "\n",
    "# select those annotations, and gather basic statistics\n",
    "study.select_annotations(users=users)\n",
    "total_features_annotations = sum(\n",
    "    [len(a.features) for a in study.annotation_selection.values()])\n",
    "selected_features = dict()\n",
    "for annotation in study.annotation_selection.values():\n",
    "    for feature in annotation.features:\n",
    "        selected_features[feature] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives some basic statistics of the study:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{1:d} readers annotated the {2:d} dermoscopic images.'.format(\n",
    "    study.name, len(users), len(study.images)))\n",
    "if print_details:\n",
    "    print(' ... per diagnosis:')\n",
    "    for (diag, image_list) in diag_images.items():\n",
    "        print(' - {0:d} in {1:s}'.format(len(image_list), diag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Out of {0:d} offered features, {1:d} were selected at least once.'.format(\n",
    "    len(study.features), len(selected_features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Each reader annotated an average of {0:.1f} features per lesion.'.format(\n",
    "    float(total_features_annotations) / len(study.annotation_selection)))\n",
    "print('In total, {0:d} feature annotations (markups) were made.'.format(\n",
    "    total_features_annotations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some additional computations for complex statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute minimum and maximum number of features (per image/diagnosis)\n",
    "(fmin, fmin_std, fmin_diag) = (85.0, 0.0, None)\n",
    "(fmax, fmax_std, fmax_diag) = (0.0, 0.0, None)\n",
    "if print_details:\n",
    "    print('On average, images with diagnosis ...')\n",
    "for diagnosis in sorted(diag_images.keys()):\n",
    "    study.select_annotations(images=diag_images[diagnosis], users=users)\n",
    "    ao = [a for a in study.annotation_selection.values()]\n",
    "    fn = [None] * len(ao)\n",
    "    for (idx,a) in enumerate(ao):\n",
    "        fn[idx] = len(a.features)\n",
    "    (m,s) = mean_std(fn)\n",
    "    if m < fmin:\n",
    "        (fmin, fmin_std, fmin_diag) = (m, s, diagnosis)\n",
    "    if m > fmax:\n",
    "        (fmax, fmax_std, fmax_diag) = (m, s, diagnosis)\n",
    "    if print_details:\n",
    "        print(' - \"{0:s}\" have {1:.2f} ± {2:.2f} annotations.'.format(\n",
    "            diagnosis, m, s))\n",
    "print('Based on the diagnosis, the number of features per image varied from')\n",
    "print('{0:.2f} (±{1:.2f}) for {2:s} to {3:.2f} (±{4:.2f}) for {5:s}.'.format(\n",
    "    fmin, fmin_std, fmin_diag, fmax, fmax_std, fmax_diag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each image, test whether all five raters agreed on one feature\n",
    "image_agreed = [False] * len(study.images)\n",
    "image_agreed_features = [[] for l in range(len(study.images))]\n",
    "image_orphan_features = []\n",
    "for (idx, image) in enumerate(study.images):\n",
    "    image_id = image['_id']\n",
    "    study.select_annotations(images=[image_id], users=users)\n",
    "    ao = [a for a in study.annotation_selection.values()]\n",
    "    for feature in ao[0].features.keys():\n",
    "        agreed = [False] * len(ao)\n",
    "        feature_syns = api.feature_synonyms(feature)\n",
    "        for (aidx, a) in enumerate(ao):\n",
    "            for f in feature_syns:\n",
    "                if f in a.features:\n",
    "                    agreed[aidx] = True\n",
    "                    break\n",
    "        if all(agreed):\n",
    "            image_agreed[idx] = True\n",
    "            image_agreed_features[idx].append(feature)\n",
    "    for (aidx1, a1) in enumerate(ao):\n",
    "        for f1 in a1.features.keys():\n",
    "            feature_syns = api.feature_synonyms(feature)\n",
    "total_agreements = 0\n",
    "if print_details:\n",
    "    print('Feature-in-image agreements:')\n",
    "for (image, a, af) in zip(study.images, image_agreed, image_agreed_features):\n",
    "    if a:\n",
    "        total_agreements += len(af)\n",
    "        image_name = image['name']\n",
    "        image_diag = study.meta_data['diagnosis'][image_name]\n",
    "        if print_details:\n",
    "            print(' - {0:s} ({1:s}): {2:s}'.format(image_name,\n",
    "                image_diag, ', '.join(af)))\n",
    "print('There were a total of {0:d} feature-in-image agreements.'.format(\n",
    "    total_agreements))\n",
    "print(('These were reached in a total of {0:d} images.').format(\n",
    "    numpy.sum(image_agreed)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count orphan features\n",
    "orphans = 0\n",
    "orphan_image_features = []\n",
    "orphan_features = dict()\n",
    "for (idx, image) in enumerate(study.images):\n",
    "    image_id = image['_id']\n",
    "    image_name = image['name']\n",
    "    study.select_annotations(images=[image_id], users=users)\n",
    "    ao = [a for a in study.annotation_selection.values()]\n",
    "    for (aidx, a) in enumerate(ao):\n",
    "        for feature in a.features:\n",
    "            is_orphan = True\n",
    "            feature_syns = api.feature_synonyms(feature)\n",
    "            for (aidx2, a2) in enumerate(ao):\n",
    "                if aidx == aidx2:\n",
    "                    continue\n",
    "                for feature2 in a2.features:\n",
    "                    if feature2 in feature_syns:\n",
    "                        is_orphan = False\n",
    "                        break\n",
    "                if not is_orphan:\n",
    "                    break\n",
    "            if is_orphan:\n",
    "                orphans += 1\n",
    "                orphan_image_features.append(feature + ' in ' + \n",
    "                    image_name + ' by ' + a.user['name'])\n",
    "                if not feature_syns[0] in orphan_features:\n",
    "                    orphan_features[feature_syns[0]] = 0\n",
    "                orphan_features[feature_syns[0]] += 1\n",
    "print('An orphan observation of a feature occurred {0:d} times.'.format(\n",
    "    orphans))\n",
    "if print_details:\n",
    "    print('{0:d} orphan features were selected:'.format(orphans))\n",
    "    for orphaned in orphan_image_features:\n",
    "        print(' - ' + orphaned)\n",
    "    print('Presenting by list of features (collapsing synonyms):')\n",
    "    for feature in sorted(orphan_features.keys()):\n",
    "        print(' - {0:-2d} times \"{1:s}\"'.format(\n",
    "            orphan_features[feature], feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many exemplar feature annotations for each image with an exemplar?\n",
    "total_exemplar_images = 0\n",
    "total_found_direct = 0\n",
    "total_found_list = []\n",
    "total_found_category = 0\n",
    "total_found_specific = 0\n",
    "for exemplar in sorted(exem_images.keys()):\n",
    "    images = exem_images[exemplar]\n",
    "    if print_details:\n",
    "        print('Exemplar \"{0:s}\" with {1:d} images:'.format(\n",
    "            exemplar, len(images)))\n",
    "    for image in images:\n",
    "        total_exemplar_images += 1\n",
    "        imag_diag = study.meta_data['diagnosis'][image]\n",
    "        study.select_annotations(images=[image], users=users)\n",
    "        ao = [a for a in study.annotation_selection.values()]\n",
    "        found_direct = 0\n",
    "        found_category = 0\n",
    "        found_specific = 0\n",
    "        for (idx,a) in enumerate(ao):\n",
    "            if exemplar in a.features:\n",
    "                found_direct += 1\n",
    "                found_category += 1\n",
    "                found_specific +=1\n",
    "                continue\n",
    "            found_at_all = False\n",
    "            for feature in a.features:\n",
    "                feature = feature.split(' : ')\n",
    "                if exemplar[0:len(feature[0])] == feature[0]:\n",
    "                    found_category += 1\n",
    "                    found_at_all = True\n",
    "                if feature[-1] in exemplar:\n",
    "                    found_specific += 1\n",
    "                    found_at_all = True\n",
    "                if found_at_all:\n",
    "                    break\n",
    "        if found_direct == len(ao):\n",
    "            total_found_direct += 1\n",
    "            total_found_list.append(image)\n",
    "        if found_specific == len(ao):\n",
    "            total_found_specific += 1\n",
    "        if found_category == len(ao):\n",
    "            total_found_category += 1\n",
    "        if print_details:\n",
    "            print((' - {0:s} ({1:s}) has {2:d} annotations; ' +\n",
    "                   '{3:d}, {4:d}, and {5:d} with the full, category, ' +\n",
    "                   'and specific exemplar').format(image, imag_diag,\n",
    "                    len(ao), found_direct, found_category, found_specific))\n",
    "print('Out of {0:d} images with an exemplar, all readers identified this'.format(\n",
    "    total_exemplar_images))\n",
    "print('feature {0:d} times, with {1:d} category and {2:d} specific hits.'.format(\n",
    "    total_found_direct, total_found_category, total_found_specific))\n",
    "if print_details:\n",
    "    print('Direct hits:')\n",
    "    for image in total_found_list:\n",
    "        print(' - {0:s} ({1:s}, {2:s})'.format(image,\n",
    "            study.meta_data['diagnosis'][image],\n",
    "            study.meta_data['exemplar'][image]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# compute the superpixel-wise agreement\n",
    "# (i.e. where 2 or more readers all agreed or any reader\n",
    "# disagreed with the feature in the same superpixel)\n",
    "if print_details:\n",
    "    print('Per-image super-pixel agreement:')\n",
    "image_sp_stats = dict()\n",
    "total_agreed = 0\n",
    "total_disagreed = 0\n",
    "sp_agreed_features = dict()\n",
    "for (image_name, image_stats) in study_stats.items():\n",
    "    orphans = 0\n",
    "    agreed = 0\n",
    "    disagreed = 0\n",
    "    for (spidx, sp_stats) in image_stats['sp'].items():\n",
    "        sp_keys = list(sp_stats.keys())\n",
    "        for sp_key in sp_keys:\n",
    "            if not sp_key in sp_agreed_features:\n",
    "                sp_agreed_features[sp_key] = {\n",
    "                    'agreed': 0, 'disagreed': 0, 'overlap': dict()\n",
    "                }\n",
    "        if len(sp_keys) == 1:\n",
    "            if len(sp_stats[sp_keys[0]]) == 1:\n",
    "                orphans += 1\n",
    "            else:\n",
    "                agreed += 1\n",
    "                sp_agreed_features[sp_keys[0]]['agreed'] += 1\n",
    "        else:\n",
    "            disagreed += 1\n",
    "            for sp_key in sp_keys:\n",
    "                sp_agreed_features[sp_key]['disagreed'] += 1\n",
    "                for o_key in sp_keys:\n",
    "                    if sp_key != o_key:\n",
    "                        if not o_key in sp_agreed_features[sp_key]['overlap']:\n",
    "                            sp_agreed_features[sp_key]['overlap'][o_key] = 0\n",
    "                        sp_agreed_features[sp_key]['overlap'][o_key] += 1\n",
    "    total_agreed += agreed\n",
    "    total_disagreed += disagreed\n",
    "    image_sp_stats[image_name] = {\n",
    "        'orphans': orphans, 'agreed': agreed, 'disagreed': disagreed}\n",
    "    if print_details:\n",
    "        print(' - {0:s} {1:-4.1f}% agreed ({2:d} SPs, w/o orphans; {3:s})'.format(\n",
    "            image_name, 100.0 * float(agreed) / float(agreed + disagreed),\n",
    "            agreed + disagreed, study.meta_data['diagnosis'][image_name]))\n",
    "print('Total agreement {0:-4.1f}% ({1:d} out of {2:d} total superpixels)'.format(\n",
    "    100.0 * float(total_agreed) / float(total_agreed + total_disagreed),\n",
    "    total_agreed, total_agreed + total_disagreed))\n",
    "if print_details:\n",
    "    print('Agreement by feature:')\n",
    "    for sp_key in sorted(sp_agreed_features.keys()):\n",
    "        sp_agreement = sp_agreed_features[sp_key]\n",
    "        print(' - {0:-4.1f}% agreement for {1:s} ({2:d} SPs)'.format(\n",
    "            100.0 * float(sp_agreement['agreed']) /\n",
    "            float(sp_agreement['agreed'] + sp_agreement['disagreed']),\n",
    "            sp_key, sp_agreement['agreed'] + sp_agreement['disagreed']))\n",
    "        if print_fine_details:\n",
    "            for o_key in sorted(sp_agreement['overlap'].keys()):\n",
    "                print('   - {0:-3d} overlapped with {1:s}'.format(\n",
    "                    sp_agreement['overlap'][o_key], o_key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heatmaps\n",
    "\n",
    "The images below show (1) a demonstration of people using\n",
    "different terms for the same feature, (2) people agreeing\n",
    "agreeing on one specific term (but not others), and (3)\n",
    "everybody agreeing on the (singular) term in an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show two images (heatmaps) of the study with agreement examples\n",
    "study_folder = doc_folder + 'EASY' + os.sep + 'PILOT' + os.sep\n",
    "print('(1)')\n",
    "api.show_image_in_notebook(\n",
    "    api.read_image(study_folder + 'ISIC_0016094.jpg'),\n",
    "    figsize=(15,15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('(2)')\n",
    "api.show_image_in_notebook(\n",
    "    api.read_image(study_folder + 'ISIC_0016128.jpg'),\n",
    "    figsize=(15,15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('(3)')\n",
    "api.show_image_in_notebook(\n",
    "    api.read_image(study_folder + 'ISIC_0015549.jpg'),\n",
    "    figsize=(15,15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mix_colors = False\n",
    "underlay_gray = 0.8\n",
    "study_stats = study.image_heatmaps(study_folder,\n",
    "    image_sel=['name', 'in', ['ISIC_0015549','ISIC_0016094','ISIC_0016128']], users=users,\n",
    "    mix_colors=mix_colors, underlay_gray=underlay_gray, resize_output=4096, font_size=144.0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
