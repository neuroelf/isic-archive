{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methods for achieving expert agreement of clinical images: the Medical Annotation and Review of Superpixels (MARk-SUP)\n",
    "## Web-based expert annotation platform piloted for expert annotation and quantitative analysis of dermoscopic features\n",
    "\n",
    "### *Online supplementary Jupyter notebook with analyses*\n",
    "\n",
    "The cells in this notebook can be run in succession, or, as\n",
    "desired, cell-by-cell.\n",
    "\n",
    "**Please note:** the first five cells **MUST** be run in order\n",
    "to establish the necessary variables in the workspace of the\n",
    "python kernel!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "\n",
    "import imageio\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from isicarchive import font, func, imfunc\n",
    "from isicarchive.api import IsicApi\n",
    "\n",
    "# function for mean and sample STD\n",
    "def mean_std(a:list, is_sample:bool=True):\n",
    "    ddof = 1 if is_sample else 0\n",
    "    return (numpy.mean(a), numpy.std(a, ddof=ddof))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings\n",
    "print_details = True # set to True for details in the print-out\n",
    "print_fine_details = False # for even more details\n",
    "\n",
    "heatmap_mix_colors = False # set to True for mixed rather than striped patches\n",
    "heatmap_underlay_gray = 0.8 # remove this much color from images for heatmaps\n",
    "heatmap_resize_output = 4096 # set heatmap output size (prior to montage)\n",
    "heatmap_legend_font_size = 144.0 # legend font-size (default, prior to fitting)\n",
    "\n",
    "overlap_compute_smcc = False # also compute smoothed-cross-correlation (masks)\n",
    "overlap_colormap = 'Greys' # colormap for overlap confusion matrices\n",
    "overlap_blow_up = 24 # blow-up factor (for each cell)\n",
    "overlap_remove_cats = ['Nail lesions'] # remove these categories from detail\n",
    "\n",
    "sp_minpairs = 3\n",
    "sp_diag_minpairs = 2\n",
    "sp_thresh_min = 2.0 / 3.0\n",
    "sp_thresh_max = 3.0 / 2.0\n",
    "sp_list_thresh = 0.5\n",
    "\n",
    "calibri = font.Font('calibri') # font to use (currently only one available!)\n",
    "\n",
    "# please change the username if you wish to re-run the notebook!\n",
    "username = 'weberj3@mskcc.org'\n",
    "\n",
    "# root folder for all ISIC related data\n",
    "doc_folder = 'Z:\\\\10.Imaging Informatics\\\\'\n",
    "\n",
    "# cache folder\n",
    "cache_folder = doc_folder + 'ISIC' + os.sep + 'cache'\n",
    "\n",
    "# show URL requests (for debugging purposes)\n",
    "debug = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate API object\n",
    "api = IsicApi(username, cache_folder=cache_folder, debug=debug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# study folder\n",
    "study_folder = doc_folder + 'EASY' + os.sep + 'PILOT' + os.sep\n",
    "\n",
    "# load study and data\n",
    "study = api.study('ISIC Annotation Study - All Features')\n",
    "study.cache_image_data()\n",
    "study.load_annotations()\n",
    "\n",
    "# load meta data\n",
    "meta_data_url = ('https://raw.githubusercontent.com/neuroelf/' +\n",
    "    'isicarchive/master/data/EASY_pilot_diagnoses.csv')\n",
    "study.load_meta_data(meta_data_url, list_to_dict=True,\n",
    "    dict_key='name', extract_key=['diagnosis', 'exemplar'])\n",
    "\n",
    "# and create a dictionary mapping diagnosis to a list of images\n",
    "diag_images = dict()\n",
    "for (name, diag) in study.meta_data['diagnosis'].items():\n",
    "    if not diag in diag_images:\n",
    "        diag_images[diag] = []\n",
    "    diag_images[diag].append(name)\n",
    "\n",
    "# same for exemplar features\n",
    "exem_images = dict()\n",
    "for (name, exemplar) in study.meta_data['exemplar'].items():\n",
    "    if not exemplar:\n",
    "        continue\n",
    "    if not exemplar in exem_images:\n",
    "        exem_images[exemplar] = []\n",
    "    exem_images[exemplar].append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select only from users that completed the study\n",
    "image_names = [img['name'] for img in study.images]\n",
    "num_images = len(study.images)\n",
    "users = [u for (u,c) in study.user_completion.items() if c==num_images]\n",
    "study.select_annotations(users=users)\n",
    "user_names = {u['_id']: u['name'].replace('User ', '') for u in study.users}\n",
    "user_idx = dict()\n",
    "for (idx, u) in enumerate(users):\n",
    "    user_idx[u] = idx\n",
    "\n",
    "# number of all annotations (across users, images, features)\n",
    "total_features_annotations = sum(\n",
    "    [len(a.features) for a in study.annotation_selection.values()])\n",
    "\n",
    "# determine which features were used\n",
    "selected_features = dict()\n",
    "for annotation in study.annotation_selection.values():\n",
    "    for feature in annotation.features:\n",
    "        selected_features[feature] = True\n",
    "\n",
    "# and create necessary lists\n",
    "full_features_list = sorted(list([f['id'] for f in study.features]))\n",
    "features_list = sorted(selected_features.keys())\n",
    "num_features = len(features_list)\n",
    "features_idx = dict()\n",
    "for (feat_idx, feat_name) in enumerate(features_list):\n",
    "    features_idx[feat_name] = feat_idx\n",
    "category_list = sorted(list(set([v.split(' : ')[0] for v in features_list])))\n",
    "num_categories = len(category_list)\n",
    "category_idx = dict()\n",
    "for (cat_idx, cat_name) in enumerate(category_list):\n",
    "    category_idx[cat_name] = cat_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an optional cell (for heatmaps and overlap statistics; the\n",
    "results of which are needed for some cells below, but the computation\n",
    "takes a lot of time, so it's split out into a separate cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create heatmaps with default settings (if not yet done, about 30 minutes)\n",
    "study_stats_file = study_folder + 'heatmap_stats.json.gz'\n",
    "if not os.path.exists(study_stats_file):\n",
    "    study_stats = study.image_heatmaps(study_folder, users=users,\n",
    "        mix_colors=heatmap_mix_colors, underlay_gray=heatmap_underlay_gray, \n",
    "        resize_output=heatmap_resize_output, font_size=heatmap_legend_font_size)\n",
    "else:\n",
    "    study_stats = func.gzip_load_var(study_stats_file)\n",
    "\n",
    "# compute feature overlap stats\n",
    "overlap_stats_file = study_folder + 'overlap_features.npz'\n",
    "if not os.path.exists(overlap_stats_file):\n",
    "    overlap_stats = study.overlap_stats(users=users, \n",
    "        compute_smcc=overlap_compute_smcc)\n",
    "    overlap_features_dice = overlap_stats[4]\n",
    "    overlap_feat_cat_dice = overlap_stats[6]\n",
    "    overlap_category_dice = overlap_stats[8]\n",
    "    if overlap_compute_smcc:\n",
    "        overlap_features_smcc = overlap_stats[10]\n",
    "        overlap_feat_cat_smcc = overlap_stats[12]\n",
    "        overlap_category_smcc = overlap_stats[14]\n",
    "        numpy.savez(overlap_stats_file,\n",
    "            overlap_features_dice=overlap_features_dice,\n",
    "            overlap_feat_cat_dice=overlap_feat_cat_dice,\n",
    "            overlap_category_dice=overlap_category_dice,\n",
    "            overlap_features_smcc=overlap_features_smcc,\n",
    "            overlap_feat_cat_smcc=overlap_feat_cat_smcc,\n",
    "            overlap_category_smcc=overlap_category_smcc)\n",
    "    else:\n",
    "        numpy.savez(overlap_stats_file,\n",
    "            overlap_features_dice=overlap_features_dice,\n",
    "            overlap_feat_cat_dice=overlap_feat_cat_dice,\n",
    "            overlap_category_dice=overlap_category_dice)\n",
    "overlap_stats = numpy.load(overlap_stats_file)\n",
    "overlap_features_dice = overlap_stats.get('overlap_features_dice')\n",
    "overlap_feat_cat_dice = overlap_stats.get('overlap_feat_cat_dice')\n",
    "overlap_category_dice = overlap_stats.get('overlap_category_dice')\n",
    "if 'overlap_features_smcc' in overlap_stats.keys():\n",
    "    overlap_compute_smcc = True\n",
    "if overlap_compute_smcc:\n",
    "    try:\n",
    "        overlap_features_smcc = overlap_stats.get('overlap_features_smcc')\n",
    "        overlap_feat_cat_smcc = overlap_stats.get('overlap_feat_cat_smcc')\n",
    "        overlap_category_smcc = overlap_stats.get('overlap_category_smcc')\n",
    "    except:\n",
    "        overlap_compute_smcc = False\n",
    "\n",
    "# select those annotations, and gather basic statistics\n",
    "selected_annotations = study.select_annotations(users=users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives some basic statistics of the study:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{1:d} readers annotated the {2:d} dermoscopic images.'.format(\n",
    "    study.name, len(users), len(study.images)))\n",
    "if print_details:\n",
    "    print(' ... per diagnosis:')\n",
    "    for (diag, image_list) in diag_images.items():\n",
    "        print(' - {0:d} in {1:s}'.format(len(image_list), diag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Out of {0:d} offered features, {1:d} were selected at least once.'.format(\n",
    "    len(study.features), len(selected_features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Each reader annotated an average of {0:.1f} features per lesion.'.format(\n",
    "    float(total_features_annotations) / len(study.annotation_selection)))\n",
    "print('In total, {0:d} feature annotations (markups) were made.'.format(\n",
    "    total_features_annotations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some additional computations for complex statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute minimum and maximum number of features (per image/diagnosis)\n",
    "(fmin, fmin_std, fmin_diag) = (85.0, 0.0, None)\n",
    "(fmax, fmax_std, fmax_diag) = (0.0, 0.0, None)\n",
    "if print_details:\n",
    "    print('On average, images with diagnosis ...')\n",
    "for diagnosis in sorted(diag_images.keys()):\n",
    "    study.select_annotations(images=diag_images[diagnosis], users=users)\n",
    "    ao = [a for a in study.annotation_selection.values()]\n",
    "    fn = [None] * len(ao)\n",
    "    for (idx,a) in enumerate(ao):\n",
    "        fn[idx] = len(a.features)\n",
    "    (m,s) = mean_std(fn)\n",
    "    if m < fmin:\n",
    "        (fmin, fmin_std, fmin_diag) = (m, s, diagnosis)\n",
    "    if m > fmax:\n",
    "        (fmax, fmax_std, fmax_diag) = (m, s, diagnosis)\n",
    "    if print_details:\n",
    "        print(' - \"{0:s}\" have {1:.2f} ± {2:.2f} annotations.'.format(\n",
    "            diagnosis, m, s))\n",
    "print('Based on the diagnosis, the number of features per image varied from')\n",
    "print('{0:.2f} (±{1:.2f}) for {2:s} to {3:.2f} (±{4:.2f}) for {5:s}.'.format(\n",
    "    fmin, fmin_std, fmin_diag, fmax, fmax_std, fmax_diag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each image, test whether all five raters agreed on one feature\n",
    "feature_annotations = dict()\n",
    "feature_annotation_stats = dict()\n",
    "user_feature_stats = [[[] for n in range(num_images)]\n",
    "    for u in range(len(user_idx))]\n",
    "for feature in full_features_list:\n",
    "    feature_annotations[feature] = dict()\n",
    "    feature_annotation_stats[feature] = None\n",
    "image_agreed = [False] * len(study.images)\n",
    "image_agreed_features = [[] for l in range(len(study.images))]\n",
    "image_orphan_features = []\n",
    "for (idx, image) in enumerate(study.images):\n",
    "    image_id = image['_id']\n",
    "    image_name = image['name']\n",
    "    study.select_annotations(images=[image_id], users=users)\n",
    "    ao = [a for a in study.annotation_selection.values()]\n",
    "    for feature in ao[0].features.keys():\n",
    "        agreed = [False] * len(ao)\n",
    "        feature_syns = api.feature_synonyms(feature)\n",
    "        for (aidx, a) in enumerate(ao):\n",
    "            for f in feature_syns:\n",
    "                if f in a.features:\n",
    "                    agreed[aidx] = True\n",
    "                    break\n",
    "        if all(agreed):\n",
    "            image_agreed[idx] = True\n",
    "            image_agreed_features[idx].append(feature)\n",
    "    for a in ao:\n",
    "        uidx = user_idx[a.user_id]\n",
    "        for (feature,fc) in a.features.items():\n",
    "            user_feature_stats[uidx][idx].append(\n",
    "                '{0:d} ({1:d})'.format(features_idx[feature], len(fc['idx'])))\n",
    "            if not feature in feature_annotations:\n",
    "                feature_annotations[feature] = dict()\n",
    "            if not image_name in feature_annotations[feature]:\n",
    "                feature_annotations[feature][image_name] = 0\n",
    "            feature_annotations[feature][image_name] += 1\n",
    "for feature in full_features_list:\n",
    "    features_annotated = [1 if v >= 3 else 0\n",
    "        for v in feature_annotations[feature].values()]\n",
    "    if not features_annotated:\n",
    "        continue\n",
    "    feature_agreed = sum(features_annotated)\n",
    "    feature_annotation_stats[feature] = feature_agreed / len(\n",
    "        feature_annotations[feature])\n",
    "feature_annotation_levels = numpy.asarray(\n",
    "    [v for v in feature_annotation_stats.values() if not v is None])\n",
    "if print_details:\n",
    "    print('Feature-in-image agreements:')\n",
    "total_agreements = 0\n",
    "for (image, a, af) in zip(study.images, image_agreed, image_agreed_features):\n",
    "    if a:\n",
    "        total_agreements += len(af)\n",
    "        image_name = image['name']\n",
    "        image_diag = study.meta_data['diagnosis'][image_name]\n",
    "        if print_details:\n",
    "            print(' - {0:s} ({1:s}): {2:s}'.format(image_name,\n",
    "                image_diag, ', '.join(af)))\n",
    "print('There were a total of {0:d} feature-in-image agreements.'.format(\n",
    "    total_agreements))\n",
    "print(('These were reached in a total of {0:d} images.').format(\n",
    "    numpy.sum(image_agreed)))\n",
    "gold_standard_50 = [feature for (feature, a_level) in feature_annotation_stats.items()\n",
    "    if a_level and a_level >= 0.5]\n",
    "print('The gold standard (of 60% agreement) was reached for ' +\n",
    "    '{0:d}'.format(len(gold_standard_50)) + ' features:')\n",
    "for feature in gold_standard_50:\n",
    "    print(' - {0:.1f}% cases for feature \"{1:s}\"'.format(\n",
    "        100.0 * feature_annotation_stats[feature], feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count features, including orphans\n",
    "feature_markups = dict()\n",
    "feature_in_images = dict()\n",
    "agreed_2 = dict()\n",
    "agreed_3 = dict()\n",
    "agreed_4 = dict()\n",
    "agreed_5 = dict()\n",
    "for feat_name in features_list:\n",
    "    feature_markups[feat_name] = 0\n",
    "    feature_in_images[feat_name] = set()\n",
    "    agreed_2[feat_name] = []\n",
    "    agreed_3[feat_name] = []\n",
    "    agreed_4[feat_name] = []\n",
    "    agreed_5[feat_name] = []\n",
    "orphans = 0\n",
    "orphan_image_features = []\n",
    "orphan_features = dict()\n",
    "benign_diag_images = []\n",
    "benign_diag_features = dict()\n",
    "malignant_diag_images = []\n",
    "malignant_diag_features = dict()\n",
    "unclear_diag_images = []\n",
    "unclear_diag_features = dict()\n",
    "user_diagnosis = {u: [] for u in users}\n",
    "for (idx, image) in enumerate(study.images):\n",
    "    image_id = image['_id']\n",
    "    image_name = image['name']\n",
    "    study.select_annotations(images=[image_id], users=users)\n",
    "    ao = [a for a in study.annotation_selection.values()]\n",
    "    diag_benign = False\n",
    "    diag_malignant = False\n",
    "    diag_unclear = False\n",
    "    diag_unknown = False\n",
    "    user_diag = {u: False for u in users}\n",
    "    for a in ao:\n",
    "        user_diag[a.user_id] = True\n",
    "        try:\n",
    "            image_diag = a.responses['Benign or Malignant']\n",
    "            user_diagnosis[a.user_id].append(image_diag)\n",
    "            if image_diag[0] == 'B':\n",
    "                diag_benign = True\n",
    "            elif image_diag[0] == 'M':\n",
    "                diag_malignant = True\n",
    "        except:\n",
    "            user_diagnosis[a.user_id].append('Unsure')\n",
    "            diag_unknown = True\n",
    "            pass\n",
    "    for (u, u_d) in user_diag.items():\n",
    "        if not u_d:\n",
    "            user_diagnosis[u].append(None)\n",
    "    if diag_benign and diag_malignant:\n",
    "        diag_unclear = True\n",
    "        unclear_diag_images.append(image_id)\n",
    "    elif diag_benign and not diag_unknown:\n",
    "        benign_diag_images.append(image_id)\n",
    "    elif diag_malignant and not diag_unknown:\n",
    "        malignant_diag_images.append(image_id)\n",
    "    for feature in features_list:\n",
    "        fcount = 0\n",
    "        for a in ao:\n",
    "            if feature in a.features:\n",
    "                fcount += 1\n",
    "                if diag_unclear:\n",
    "                    if not feature in unclear_diag_features:\n",
    "                        unclear_diag_features[feature] = []\n",
    "                    unclear_diag_features[feature].append(image_id)\n",
    "                elif diag_benign and not diag_unknown:\n",
    "                    if not feature in benign_diag_features:\n",
    "                        benign_diag_features[feature] = []\n",
    "                    benign_diag_features[feature].append(image_id)\n",
    "                elif diag_malignant and not diag_unknown:\n",
    "                    if not feature in malignant_diag_features:\n",
    "                        malignant_diag_features[feature] = []\n",
    "                    malignant_diag_features[feature].append(image_id)\n",
    "        if fcount > 1:\n",
    "            agreed_2[feature].append(image_name)\n",
    "        if fcount > 2:\n",
    "            agreed_3[feature].append(image_name)\n",
    "        if fcount > 3:\n",
    "            agreed_4[feature].append(image_name)\n",
    "        if fcount > 4:\n",
    "            agreed_5[feature].append(image_name)\n",
    "    for (aidx, a) in enumerate(ao):\n",
    "        for feature in a.features:\n",
    "            feature_markups[feature] += 1\n",
    "            feature_in_images[feature].add(image_name)\n",
    "            is_orphan = True\n",
    "            feature_syns = api.feature_synonyms(feature)\n",
    "            for (aidx2, a2) in enumerate(ao):\n",
    "                if aidx == aidx2:\n",
    "                    continue\n",
    "                for feature2 in a2.features:\n",
    "                    if feature2 in feature_syns:\n",
    "                        is_orphan = False\n",
    "                        break\n",
    "                if not is_orphan:\n",
    "                    break\n",
    "            if is_orphan:\n",
    "                orphans += 1\n",
    "                orphan_image_features.append(feature + ' in ' + \n",
    "                    image_name + ' by ' + a.user['name'])\n",
    "                if not feature_syns[0] in orphan_features:\n",
    "                    orphan_features[feature_syns[0]] = 0\n",
    "                orphan_features[feature_syns[0]] += 1\n",
    "print('An orphan observation of a feature occurred {0:d} times.'.format(\n",
    "    orphans))\n",
    "if print_details:\n",
    "    print('{0:d} orphan features were selected:'.format(orphans))\n",
    "    for orphaned in orphan_image_features:\n",
    "        print(' - ' + orphaned)\n",
    "    print('Presenting by list of features:')\n",
    "    for feature in sorted(orphan_features.keys()):\n",
    "        print(' - {0:-2d} times \"{1:s}\"'.format(\n",
    "            orphan_features[feature], feature))\n",
    "    print('')\n",
    "print('Out of the {0:d} images, {1:d} were given mixed diagnoses.'.format(\n",
    "    num_images, len(unclear_diag_images)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many exemplar feature annotations for each image with an exemplar?\n",
    "gold_standard_examplars = 0\n",
    "total_exemplar_images = 0\n",
    "total_found_direct = 0\n",
    "total_found_list = []\n",
    "total_found_category = 0\n",
    "total_found_specific = 0\n",
    "for exemplar in sorted(exem_images.keys()):\n",
    "    images = exem_images[exemplar]\n",
    "    if print_details:\n",
    "        print('Exemplar \"{0:s}\" with {1:d} images:'.format(\n",
    "            exemplar, len(images)))\n",
    "    for image in images:\n",
    "        total_exemplar_images += 1\n",
    "        imag_diag = study.meta_data['diagnosis'][image]\n",
    "        study.select_annotations(images=[image], users=users)\n",
    "        ao = [a for a in study.annotation_selection.values()]\n",
    "        found_direct = 0\n",
    "        found_category = 0\n",
    "        found_specific = 0\n",
    "        for (idx,a) in enumerate(ao):\n",
    "            if exemplar in a.features:\n",
    "                found_direct += 1\n",
    "                found_category += 1\n",
    "                found_specific +=1\n",
    "                continue\n",
    "            found_at_all = False\n",
    "            for feature in a.features:\n",
    "                feature = feature.split(' : ')\n",
    "                if exemplar[0:len(feature[0])] == feature[0]:\n",
    "                    found_category += 1\n",
    "                    found_at_all = True\n",
    "                if feature[-1] in exemplar:\n",
    "                    found_specific += 1\n",
    "                    found_at_all = True\n",
    "                if found_at_all:\n",
    "                    break\n",
    "        if found_direct >= 3:\n",
    "            gold_standard_examplars += 1\n",
    "        if found_direct == len(ao):\n",
    "            total_found_direct += 1\n",
    "            total_found_list.append(image)\n",
    "        if found_specific == len(ao):\n",
    "            total_found_specific += 1\n",
    "        if found_category == len(ao):\n",
    "            total_found_category += 1\n",
    "        if print_details:\n",
    "            print((' - {0:s} ({1:s}) has {2:d} annotations; ' +\n",
    "                   '{3:d}, {4:d}, and {5:d} with the full, category, ' +\n",
    "                   'and specific exemplar').format(image, imag_diag,\n",
    "                    len(ao), found_direct, found_category, found_specific))\n",
    "print(('Out of {0:d} images with an exemplar, the gold standard for the\\n' +\n",
    "    'exemplar image (60% agreement) was reached {1:d} times (~{2:d}%).').format(\n",
    "    total_exemplar_images, gold_standard_examplars,\n",
    "    int(100*gold_standard_examplars/total_exemplar_images)))\n",
    "print('And out of these same images, all readers identified this')\n",
    "print('feature {0:d} times, with {1:d} category and {2:d} specific hits.'.format(\n",
    "    total_found_direct, total_found_category, total_found_specific))\n",
    "if print_details:\n",
    "    print('Direct hits:')\n",
    "    for image in total_found_list:\n",
    "        print(' - {0:s} ({1:s}, {2:s})'.format(image,\n",
    "            study.meta_data['diagnosis'][image],\n",
    "            study.meta_data['exemplar'][image]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# compute the superpixel-wise agreement\n",
    "# (i.e. where 2 or more readers all agreed or any reader\n",
    "# disagreed with the feature in the same superpixel)\n",
    "print_fine_details=False\n",
    "if print_details:\n",
    "    print('Per-image super-pixel agreement:')\n",
    "image_sp_stats = dict()\n",
    "gs_agreed = 0\n",
    "total_agreed = 0\n",
    "total_disagreed = 0\n",
    "sp_agreed_features = dict()\n",
    "for (image_name, image_stats) in study_stats.items():\n",
    "    orphans = 0\n",
    "    agreed = 0\n",
    "    disagreed = 0\n",
    "    for (spidx, sp_stats) in image_stats['sp'].items():\n",
    "        sp_keys = list(sp_stats.keys())\n",
    "        for sp_key in sp_keys:\n",
    "            if not sp_key in sp_agreed_features:\n",
    "                sp_agreed_features[sp_key] = {\n",
    "                    'agreed': 0,\n",
    "                    'disagreed': 0,\n",
    "                    'gs_agreed': 0,\n",
    "                    'overlap': dict(),\n",
    "                }\n",
    "        if len(sp_keys) == 1:\n",
    "            if len(sp_stats[sp_keys[0]]) == 1:\n",
    "                orphans += 1\n",
    "            else:\n",
    "                agreed += 1\n",
    "                sp_agreed_features[sp_keys[0]]['agreed'] += 1\n",
    "        else:\n",
    "            disagreed += 1\n",
    "            for sp_key in sp_keys:\n",
    "                sp_agreed_features[sp_key]['disagreed'] += 1\n",
    "                if len(sp_stats[sp_key]) >= 3:\n",
    "                    sp_agreed_features[sp_key]['gs_agreed'] += 1\n",
    "                for o_key in sp_keys:\n",
    "                    if sp_key != o_key:\n",
    "                        if not o_key in sp_agreed_features[sp_key]['overlap']:\n",
    "                            sp_agreed_features[sp_key]['overlap'][o_key] = 0\n",
    "                        sp_agreed_features[sp_key]['overlap'][o_key] += 1\n",
    "    total_agreed += agreed\n",
    "    total_disagreed += disagreed\n",
    "    image_sp_stats[image_name] = {\n",
    "        'orphans': orphans, 'agreed': agreed, 'disagreed': disagreed}\n",
    "    if print_details:\n",
    "        print(' - {0:s} {1:-4.1f}% agreed ({2:d} SPs, w/o orphans; {3:s})'.format(\n",
    "            image_name, 100.0 * float(agreed) / float(agreed + disagreed),\n",
    "            agreed + disagreed, study.meta_data['diagnosis'][image_name]))\n",
    "print('Total agreement {0:-4.1f}% ({1:d} out of {2:d} total superpixels)'.format(\n",
    "    100.0 * float(total_agreed) / float(total_agreed + total_disagreed),\n",
    "    total_agreed, total_agreed + total_disagreed))\n",
    "if print_details:\n",
    "    print('Agreement by feature:')\n",
    "    for sp_key in sorted(sp_agreed_features.keys()):\n",
    "        sp_agreement = sp_agreed_features[sp_key]\n",
    "        print(' - {0:-4.1f}% GS / {1:-4.1f}% full agreement for {2:s} ({3:d} SPs)'.format(\n",
    "            100.0 * float(sp_agreement['gs_agreed']) /\n",
    "            float(sp_agreement['agreed'] + sp_agreement['disagreed']),\n",
    "            100.0 * float(sp_agreement['agreed']) /\n",
    "            float(sp_agreement['agreed'] + sp_agreement['disagreed']),\n",
    "            sp_key, sp_agreement['agreed'] + sp_agreement['disagreed']))\n",
    "        if print_fine_details:\n",
    "            for o_key in sorted(sp_agreement['overlap'].keys()):\n",
    "                print('   - {0:-3d} overlapped with {1:s}'.format(\n",
    "                    sp_agreement['overlap'][o_key], o_key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute feature-based super-pixel co-occurrences\n",
    "benign_features = dict()\n",
    "malignant_features = dict()\n",
    "category_sp_hits = numpy.zeros((num_categories, num_categories,))\n",
    "category_sp_miss = numpy.zeros((num_categories, num_categories,))\n",
    "category_sp_basis = numpy.zeros((num_categories, num_categories,))\n",
    "feature_sp_hits = numpy.zeros((num_features, num_features,))\n",
    "feature_sp_miss = numpy.zeros((num_features, num_features,))\n",
    "feature_sp_basis = numpy.zeros((num_features, num_features,))\n",
    "feat_cat_sp_hits = numpy.zeros((num_features, num_categories,))\n",
    "feat_cat_sp_miss = numpy.zeros((num_features, num_categories,))\n",
    "feat_cat_sp_basis = numpy.zeros((num_features, num_categories,))\n",
    "sp_pairs_overlap = dict()\n",
    "sp_pairs_overlap_diag = dict()\n",
    "sp_thresh_min = 2.0 / 3.0\n",
    "sp_thresh_max = 3.0 / 2.0\n",
    "for (idx, image) in enumerate(study.images):\n",
    "    image_id = image['_id']\n",
    "    study.select_annotations(images=[image_id], users=users)\n",
    "    ao = [a for a in study.annotation_selection.values()]\n",
    "    for (aidx, a) in enumerate(ao):\n",
    "        for (feature, fcont) in a.features.items():\n",
    "            feature_cat = feature.split(' : ')[0]\n",
    "            try:\n",
    "                feature_diag = (a.responses['Benign or Malignant']\n",
    "                    + '>' + feature)\n",
    "                if feature_diag[0] == 'B':\n",
    "                    if not feature in benign_features:\n",
    "                        benign_features[feature] = []\n",
    "                    benign_features[feature].append(image_id)\n",
    "                elif feature_diag[0] == 'M':\n",
    "                    if not feature in malignant_features:\n",
    "                        malignant_features[feature] = []\n",
    "                    malignant_features[feature].append(image_id)\n",
    "            except:\n",
    "                feature_diag = 'Unsure>' + feature\n",
    "            fnum = features_idx[feature]\n",
    "            cnum = category_idx[feature_cat]\n",
    "            fidx = set(fcont['idx'])\n",
    "            didx = float(len(fidx))\n",
    "            for (aidx2, a2) in enumerate(ao):\n",
    "                if aidx == aidx2:\n",
    "                    continue\n",
    "                for (feature2, fcont2) in a2.features.items():\n",
    "                    feature2_cat = feature2.split(' : ')[0]\n",
    "                    try:\n",
    "                        feature2_diag = (a2.responses['Benign or Malignant']\n",
    "                            + '>' + feature2)\n",
    "                    except:\n",
    "                        feature2_diag = 'Unsure>' + feature2\n",
    "                    fnum2 = features_idx[feature2]\n",
    "                    cnum2 = category_idx[feature2_cat]\n",
    "                    fidx2 = set(fcont2['idx'])\n",
    "                    didx2 = float(len(fidx2))\n",
    "                    finter = fidx.intersection(fidx2)\n",
    "                    finterlen = float(len(finter))\n",
    "                    category_sp_hits[cnum,cnum2] += finterlen\n",
    "                    category_sp_hits[cnum2,cnum] += finterlen\n",
    "                    category_sp_miss[cnum,cnum2] += didx - finterlen\n",
    "                    category_sp_miss[cnum2,cnum] += didx2 - finterlen\n",
    "                    category_sp_basis[cnum,cnum2] += didx\n",
    "                    category_sp_basis[cnum2,cnum] += didx2\n",
    "                    feature_sp_hits[fnum,fnum2] += finterlen\n",
    "                    feature_sp_hits[fnum2,fnum] += finterlen\n",
    "                    feature_sp_miss[fnum,fnum2] += didx - finterlen\n",
    "                    feature_sp_miss[fnum2,fnum] += didx2 - finterlen\n",
    "                    feature_sp_basis[fnum,fnum2] += didx\n",
    "                    feature_sp_basis[fnum2,fnum] += didx2\n",
    "                    feat_cat_sp_hits[fnum,cnum2] += finterlen\n",
    "                    feat_cat_sp_hits[fnum2,cnum] += finterlen\n",
    "                    feat_cat_sp_miss[fnum,cnum2] += didx - finterlen\n",
    "                    feat_cat_sp_miss[fnum2,cnum] += didx2 - finterlen\n",
    "                    feat_cat_sp_basis[fnum,cnum2] += didx\n",
    "                    feat_cat_sp_basis[fnum2,cnum] += didx2\n",
    "                    if aidx >= aidx2 or feature == feature2:\n",
    "                        continue\n",
    "                    if didx < 3 or didx2 < 3:\n",
    "                        continue\n",
    "                    dfac = didx / didx2\n",
    "                    if dfac < sp_thresh_min or dfac > sp_thresh_max:\n",
    "                        continue\n",
    "                    if feature < feature2:\n",
    "                        fp = feature + ' *and* ' + feature2\n",
    "                    else:\n",
    "                        fp = feature2 + ' *and* ' + feature\n",
    "                    fp_dice = 2 * finterlen / (didx + didx2)\n",
    "                    if not fp in sp_pairs_overlap:\n",
    "                        sp_pairs_overlap[fp] = []\n",
    "                    sp_pairs_overlap[fp].append(fp_dice)\n",
    "                    if feature_diag < feature2_diag:\n",
    "                        fp = feature_diag + ' *and* ' + feature2_diag\n",
    "                    else:\n",
    "                        fp = feature2_diag + ' *and* ' + feature_diag\n",
    "                    if not fp in sp_pairs_overlap_diag:\n",
    "                        sp_pairs_overlap_diag[fp] = []\n",
    "                    sp_pairs_overlap_diag[fp].append(fp_dice)\n",
    "category_sp_basis[category_sp_basis == 0.0] = 1.0\n",
    "category_sp_hits = category_sp_hits / category_sp_basis\n",
    "category_sp_miss = category_sp_miss / category_sp_basis\n",
    "feature_sp_basis[feature_sp_basis == 0.0] = 1.0\n",
    "feature_sp_hits = feature_sp_hits / feature_sp_basis\n",
    "feature_sp_miss = feature_sp_miss / feature_sp_basis\n",
    "feat_cat_sp_basis[feat_cat_sp_basis == 0.0] = 1.0\n",
    "feat_cat_sp_hits = feat_cat_sp_hits / feat_cat_sp_basis\n",
    "feat_cat_sp_miss = feat_cat_sp_miss / feat_cat_sp_basis\n",
    "sp_pairs_overlap_diagsame = {\n",
    "    fp: fp_list for (fp, fp_list) in sp_pairs_overlap_diag.items()}\n",
    "for fp in list(sp_pairs_overlap.keys()):\n",
    "    if len(sp_pairs_overlap[fp]) < sp_minpairs:\n",
    "        sp_pairs_overlap.pop(fp)\n",
    "for fp in list(sp_pairs_overlap_diag.keys()):\n",
    "    if (len(sp_pairs_overlap_diag[fp]) < sp_diag_minpairs or\n",
    "        not 'Benign' in fp or not 'Malignant' in fp):\n",
    "        sp_pairs_overlap_diag.pop(fp)\n",
    "for fp in list(sp_pairs_overlap_diagsame.keys()):\n",
    "    if (len(sp_pairs_overlap_diagsame[fp]) < sp_diag_minpairs or\n",
    "        'Unsure' in fp or\n",
    "        ('Benign' in fp and 'Malignant' in fp)):\n",
    "        sp_pairs_overlap_diagsame.pop(fp)\n",
    "sp_pairs_overlap = list(reversed(sorted(sp_pairs_overlap.items(),\n",
    "    key=lambda x: numpy.mean(x[1]))))\n",
    "sp_pairs_overlap_diag = list(reversed(sorted(sp_pairs_overlap_diag.items(),\n",
    "    key=lambda x: numpy.mean(x[1]))))\n",
    "sp_pairs_overlap_diagsame = list(reversed(sorted(sp_pairs_overlap_diagsame.items(),\n",
    "    key=lambda x: numpy.mean(x[1]))))\n",
    "sp_pairs_highoverlap = sum(\n",
    "    [1 if numpy.mean(sp[1]) >= sp_list_thresh else 0 for sp in sp_pairs_overlap])\n",
    "sp_pairs_highoverlap_diag = sum(\n",
    "    [1 if numpy.mean(sp[1]) >= sp_list_thresh else 0 for sp in sp_pairs_overlap_diag])\n",
    "sp_pairs_highoverlap_diagsame = sum(\n",
    "    [1 if numpy.mean(sp[1]) >= sp_list_thresh else 0\n",
    "     for sp in sp_pairs_overlap_diagsame])\n",
    "print(('There are {0:d} pairs of discordant features with ' +\n",
    "    'high (> {1:.2f} DICE) overlap:').format(sp_pairs_highoverlap, sp_list_thresh))\n",
    "if print_details:\n",
    "    for sp in sp_pairs_overlap:\n",
    "        sp_mean = numpy.mean(sp[1])\n",
    "        if sp_mean < sp_list_thresh:\n",
    "            break\n",
    "        print(' - {0:.1f}% ({1:d} pairs) for features {2:s}'.format(\n",
    "            100.0 * sp_mean, len(sp[1]), sp[0]))\n",
    "    print('')\n",
    "print(('For different diagnoses, there are {0:d} pairs of discordant features with ' +\n",
    "    'high (> {1:.2f} DICE) overlap:').format(sp_pairs_highoverlap_diag, sp_list_thresh))\n",
    "if print_details:\n",
    "    for sp in sp_pairs_overlap_diag:\n",
    "        sp_mean = numpy.mean(sp[1])\n",
    "        if sp_mean < sp_list_thresh:\n",
    "            break\n",
    "        print(' - {0:.1f}% ({1:d} pairs) for features {2:s}'.format(\n",
    "            100.0 * sp_mean, len(sp[1]), sp[0]))\n",
    "    print('')\n",
    "print(('For equal diagnoses, there are {0:d} pairs of discordant features with ' +\n",
    "    'high (> {1:.2f} DICE) overlap:').format(sp_pairs_highoverlap_diagsame, sp_list_thresh))\n",
    "if print_details:\n",
    "    for sp in sp_pairs_overlap_diagsame:\n",
    "        sp_mean = numpy.mean(sp[1])\n",
    "        if sp_mean < sp_list_thresh:\n",
    "            break\n",
    "        print(' - {0:.1f}% ({1:d} pairs) for features {2:s}'.format(\n",
    "            100.0 * sp_mean, len(sp[1]), sp[0]))\n",
    "    print('')\n",
    "disdiag_sp_overlap = []\n",
    "for (feature, feature_images) in benign_features.items():\n",
    "    if feature in malignant_features:\n",
    "        continue\n",
    "    for image_id in feature_images:\n",
    "        for (feature2, feature2_images) in malignant_features.items():\n",
    "            if not image_id in feature2_images:\n",
    "                continue\n",
    "            study.select_annotations(images=[image_id], users=users,\n",
    "                features=[feature, feature2])\n",
    "            ao = [a for a in study.annotation_selection.values()]\n",
    "            for (aidx, a) in enumerate(ao):\n",
    "                if not feature in a.features:\n",
    "                    continue\n",
    "                fcont = a.features[feature]\n",
    "                fidx = set(fcont['idx'])\n",
    "                didx = float(len(fidx))\n",
    "                for (aidx2, a2) in enumerate(ao):\n",
    "                    if aidx == aidx2:\n",
    "                        continue\n",
    "                    if not feature2 in a2.features:\n",
    "                        continue\n",
    "                    fcont2 = a2.features[feature2]\n",
    "                    fidx2 = set(fcont2['idx'])\n",
    "                    didx2 = float(len(fidx2))\n",
    "                    finter = fidx.intersection(fidx2)\n",
    "                    finterlen = float(len(finter))\n",
    "                    fp_dice = 2 * finterlen / (didx + didx2)\n",
    "                    if fp_dice < sp_list_thresh:\n",
    "                        continue\n",
    "                    disdiag_sp_overlap.append({\n",
    "                        'Image': a.image['name'],\n",
    "                        'Reader1': user_names[a.user_id],\n",
    "                        'Reader2': user_names[a2.user_id],\n",
    "                        'Benign': feature,\n",
    "                        'Malignant': feature2,\n",
    "                        'DICE': fp_dice,\n",
    "                    })\n",
    "for (feature, feature_images) in malignant_features.items():\n",
    "    if feature in benign_features:\n",
    "        continue\n",
    "    for image_id in feature_images:\n",
    "        for (feature2, feature2_images) in benign_features.items():\n",
    "            if not image_id in feature2_images:\n",
    "                continue\n",
    "            study.select_annotations(images=[image_id], users=users,\n",
    "                features=[feature, feature2])\n",
    "            ao = [a for a in study.annotation_selection.values()]\n",
    "            for (aidx, a) in enumerate(ao):\n",
    "                if not feature in a.features:\n",
    "                    continue\n",
    "                fcont = a.features[feature]\n",
    "                fidx = set(fcont['idx'])\n",
    "                didx = float(len(fidx))\n",
    "                for (aidx2, a2) in enumerate(ao):\n",
    "                    if aidx == aidx2:\n",
    "                        continue\n",
    "                    if not feature2 in a2.features:\n",
    "                        continue\n",
    "                    fcont2 = a2.features[feature2]\n",
    "                    fidx2 = set(fcont2['idx'])\n",
    "                    didx2 = float(len(fidx2))\n",
    "                    finter = fidx.intersection(fidx2)\n",
    "                    finterlen = float(len(finter))\n",
    "                    fp_dice = 2 * finterlen / (didx + didx2)\n",
    "                    if fp_dice < sp_list_thresh:\n",
    "                        continue\n",
    "                    disdiag_sp_overlap.append({\n",
    "                        'Image': a.image['name'],\n",
    "                        'Reader1': user_names[a2.user_id],\n",
    "                        'Reader2': user_names[a.user_id],\n",
    "                        'Benign': feature2,\n",
    "                        'Malignant': feature,\n",
    "                        'DICE': fp_dice,\n",
    "                    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Superpixel explanation (image)\n",
    "\n",
    "Superpixels are an automatic segmentation performed by the ISIC Archive,\n",
    "which then allows annotators (readers) to select specific parcels of an\n",
    "image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a heatmap with default settings (User: Liopyris)\n",
    "sample_image = api.image('ISIC_0016094')\n",
    "sample_image.load_image_data()\n",
    "sample_data = sample_image.data\n",
    "sample_image.mark_superpixels()\n",
    "sp_data = sample_image.data\n",
    "sample_image.clear_data()\n",
    "(heatmap, stats) = study.image_heatmap('ISIC_0016094',\n",
    "    mix_colors=False,underlay_gray=0.8,users=['578e64b09fc3c10d6fd12e4f'])\n",
    "sp_image = imfunc.image_mix(sp_data, heatmap)\n",
    "sp_comparison = numpy.concatenate((sample_data, sp_image), axis=1)\n",
    "api.write_image(sp_comparison, study_folder + 'ISIC_0016094+hm_w_sp.png')\n",
    "api.show_image_in_notebook(sp_comparison, max_size=1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heatmaps\n",
    "\n",
    "The images below show (1) a demonstration of people using\n",
    "different terms for the same feature, (2) people agreeing\n",
    "agreeing on one specific term (but not others), and (3)\n",
    "everybody agreeing on the (singular) term in an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show three images (heatmaps) of the study with agreement examples\n",
    "print('(1)')\n",
    "(heatmap, heatmap_stats) = study.image_heatmap('ISIC_0015549',\n",
    "    users=users, underlay_gray=heatmap_underlay_gray,\n",
    "    mix_colors=heatmap_mix_colors, resize_output=4096)\n",
    "api.show_image_in_notebook(heatmap, max_size=1024)\n",
    "print('(2)')\n",
    "(heatmap, heatmap_stats) = study.image_heatmap('ISIC_0016094',\n",
    "    users=users, underlay_gray=heatmap_underlay_gray,\n",
    "    mix_colors=heatmap_mix_colors, resize_output=4096)\n",
    "api.show_image_in_notebook(heatmap, max_size=1024)\n",
    "print('(3)')\n",
    "(heatmap, heatmap_stats) = study.image_heatmap('ISIC_0016128',\n",
    "    users=users, underlay_gray=heatmap_underlay_gray,\n",
    "    mix_colors=heatmap_mix_colors, resize_output=4096)\n",
    "api.show_image_in_notebook(heatmap, max_size=1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature overlap/confusion figure\n",
    "\n",
    "The image prepared with the code below shows the matrix of feature overlap,\n",
    "and thus confusability; collapsed across images/diagnoses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the color lookup map\n",
    "color_norm = mpl.colors.Normalize(vmin=0.0, vmax=1.0)\n",
    "color_map = cm.ScalarMappable(norm=color_norm, cmap=overlap_colormap)\n",
    "\n",
    "overlap_stats = numpy.load(overlap_stats_file)\n",
    "overlap_features_dice = overlap_stats.get('overlap_features_dice')\n",
    "overlap_feat_cat_dice = overlap_stats.get('overlap_feat_cat_dice')\n",
    "overlap_category_dice = overlap_stats.get('overlap_category_dice')\n",
    "\n",
    "# remove categories from display\n",
    "remove_cat_lines = []\n",
    "for c in overlap_remove_cats:\n",
    "    if c in category_list:\n",
    "        remove_cat_lines.append(category_list.index(c))\n",
    "remove_cat_lines = reversed(sorted(remove_cat_lines))\n",
    "for c in remove_cat_lines:\n",
    "    category_sp_hits = numpy.delete(category_sp_hits, c, axis=0)\n",
    "    category_sp_hits = numpy.delete(category_sp_hits, c, axis=1)\n",
    "    feat_cat_sp_hits = numpy.delete(feat_cat_sp_hits, c, axis=1)\n",
    "    overlap_category_dice = numpy.delete(overlap_category_dice, c, axis=0)\n",
    "    overlap_category_dice = numpy.delete(overlap_category_dice, c, axis=1)\n",
    "    overlap_feat_cat_dice = numpy.delete(overlap_feat_cat_dice, c, axis=1)\n",
    "    category_list.pop(c)\n",
    "\n",
    "# process data prior to creating the image\n",
    "white_val = numpy.uint8(255)\n",
    "feature_sp_rgb = numpy.trunc(255.0 *\n",
    "    color_map.to_rgba(feature_sp_hits)[:,:,0:3]).astype(numpy.uint8)\n",
    "feat_cat_sp_rgb = numpy.trunc(255.0 *\n",
    "    color_map.to_rgba(feat_cat_sp_hits)[:,:,0:3]).astype(numpy.uint8)\n",
    "category_sp_rgb = numpy.trunc(255.0 *\n",
    "    color_map.to_rgba(category_sp_hits)[:,:,0:3]).astype(numpy.uint8)\n",
    "overlap_features_null = numpy.isnan(overlap_features_dice)\n",
    "overlap_feat_cat_null = numpy.isnan(overlap_feat_cat_dice)\n",
    "overlap_category_null = numpy.isnan(overlap_category_dice)\n",
    "overlap_features_dice[overlap_features_null] = 0\n",
    "overlap_feat_cat_dice[overlap_feat_cat_null] = 0\n",
    "overlap_category_dice[overlap_category_null] = 0\n",
    "overlap_features_rgb = numpy.trunc(255.0 *\n",
    "    color_map.to_rgba(overlap_features_dice[:,:,0])[:,:,0:3]).astype(numpy.uint8)\n",
    "overlap_features_rgb[numpy.repeat(overlap_features_null[:,:,0:1], 3, axis=2)] = 255\n",
    "overlap_feat_cat_rgb = numpy.trunc(255.0 *\n",
    "    color_map.to_rgba(overlap_feat_cat_dice[:,:,0])[:,:,0:3]).astype(numpy.uint8)\n",
    "overlap_feat_cat_rgb[numpy.repeat(overlap_feat_cat_null[:,:,0:1], 3, axis=2)] = 255\n",
    "overlap_category_rgb = numpy.trunc(255.0 *\n",
    "    color_map.to_rgba(overlap_category_dice[:,:,0])[:,:,0:3]).astype(numpy.uint8)\n",
    "overlap_category_rgb[numpy.repeat(overlap_category_null[:,:,0:1], 3, axis=2)] = 255\n",
    "\n",
    "# add spacers spacers\n",
    "f1v = white_val * numpy.ones((overlap_category_dice.shape[0], 2, 3,),\n",
    "    dtype=numpy.uint8)\n",
    "f2v = white_val * numpy.ones((overlap_features_dice.shape[0], 2, 3,),\n",
    "    dtype=numpy.uint8)\n",
    "blank_space = white_val * numpy.ones(\n",
    "    (overlap_category_dice.shape[0], overlap_features_dice.shape[0], 3,),\n",
    "    dtype=numpy.uint8)\n",
    "hits_top_image = numpy.concatenate(\n",
    "    (category_sp_rgb, f1v, blank_space), axis=1)\n",
    "hits_bottom_image = numpy.concatenate(\n",
    "    (feat_cat_sp_rgb, f2v, feature_sp_rgb), axis=1)\n",
    "dice_top_image = numpy.concatenate(\n",
    "    (overlap_category_rgb, f1v, blank_space), axis=1)\n",
    "dice_bottom_image = numpy.concatenate(\n",
    "    (overlap_feat_cat_rgb, f2v, overlap_features_rgb), axis=1)\n",
    "f1h = white_val * numpy.ones((2, dice_top_image.shape[1], 3,), dtype=numpy.uint8)\n",
    "hits_full_image = numpy.concatenate((hits_top_image, f1h, hits_bottom_image), axis=0)\n",
    "dice_full_image = numpy.concatenate((dice_top_image, f1h, dice_bottom_image), axis=0)\n",
    "\n",
    "# blow up by factor 24 (for text attribution)\n",
    "detail_blow_up = 5 * overlap_blow_up\n",
    "hits_detail_image = numpy.repeat(numpy.repeat(\n",
    "    hits_full_image[0:len(category_list), 0:len(category_list), :],\n",
    "    detail_blow_up, axis=0), detail_blow_up, axis=1)\n",
    "hits_full_image = numpy.repeat(numpy.repeat(hits_full_image, overlap_blow_up, axis=0),\n",
    "    overlap_blow_up, axis=1)\n",
    "dice_detail_image = numpy.repeat(numpy.repeat(\n",
    "    dice_full_image[0:len(category_list), 0:len(category_list), :],\n",
    "    detail_blow_up, axis=0), detail_blow_up, axis=1)\n",
    "dice_full_image = numpy.repeat(numpy.repeat(dice_full_image, overlap_blow_up, axis=0),\n",
    "    overlap_blow_up, axis=1)\n",
    "\n",
    "# determine line positions and paint lines\n",
    "line_pos = []\n",
    "cat_name = category_list[0]\n",
    "for (idx,feature) in enumerate(features_list):\n",
    "    if not cat_name in feature:\n",
    "        line_pos.append(idx)\n",
    "        cat_name = feature.split(' : ')[0]\n",
    "line_offset = overlap_blow_up * (len(category_list) + 2) - 1\n",
    "for lp in line_pos:\n",
    "    line_xy = line_offset + overlap_blow_up * lp\n",
    "    hits_full_image[line_xy:line_xy+2,:,:] = 0\n",
    "    hits_full_image[line_offset:, line_xy:line_xy+2,:] = 0\n",
    "    dice_full_image[line_xy:line_xy+2,:,:] = 0\n",
    "    dice_full_image[line_offset:, line_xy:line_xy+2,:] = 0\n",
    "\n",
    "# create text images\n",
    "category_text = calibri.set_line(category_list, fsize=overlap_blow_up-1)\n",
    "category_text_length = [v for v in map(lambda x: x.shape[1], category_text)]\n",
    "detail_text = calibri.set_line(category_list, fsize=(3*overlap_blow_up))\n",
    "detail_text_length = [v for v in map(lambda x: x.shape[1], detail_text)]\n",
    "detail_max_length = max(detail_text_length)\n",
    "features_text = calibri.set_line(features_list, fsize=overlap_blow_up-1)\n",
    "features_text_length = [v for v in map(lambda x: x.shape[1], features_text)]\n",
    "features_max_length = max(features_text_length)\n",
    "detail_timage_x = detail_max_length + 4 * overlap_blow_up\n",
    "detail_timage = white_val * numpy.ones(\n",
    "    (dice_detail_image.shape[0], detail_timage_x, 3, ), dtype=numpy.uint8)\n",
    "text_image_y = overlap_blow_up * (2 + len(category_text) + len(features_text))\n",
    "text_image_x = features_max_length + 2 * overlap_blow_up\n",
    "text_image = white_val * numpy.ones(\n",
    "    (text_image_y, text_image_x, 3,), dtype=numpy.uint8)\n",
    "for (idx, cat_name) in enumerate(category_list):\n",
    "    line_w = category_text_length[idx]\n",
    "    line_text = white_val - numpy.repeat(\n",
    "        category_text[idx].reshape((overlap_blow_up, line_w, 1,)), 3, axis=2)\n",
    "    line_xy = idx * overlap_blow_up\n",
    "    line_x = overlap_blow_up + (features_max_length - line_w)\n",
    "    text_image[line_xy:line_xy+overlap_blow_up,line_x:line_x+line_w,:] = line_text\n",
    "    line_w = detail_text_length[idx]\n",
    "    line_text = white_val - numpy.repeat(detail_text[idx].reshape(\n",
    "        (detail_text[idx].shape[0], line_w, 1,)), 3, axis=2)\n",
    "    line_xy = (idx * 5 + 1) * overlap_blow_up\n",
    "    line_x = 2 * overlap_blow_up + (detail_max_length - line_w)\n",
    "    detail_timage[line_xy:line_xy+line_text.shape[0],line_x:line_x+line_w,:] = line_text\n",
    "for (idx, feat_name) in enumerate(features_list):\n",
    "    line_w = features_text_length[idx]\n",
    "    line_text = white_val - numpy.repeat(\n",
    "        features_text[idx].reshape((overlap_blow_up, line_w, 1,)), 3, axis=2)\n",
    "    line_xy = (len(category_list) + 2 + idx) * overlap_blow_up\n",
    "    line_x = overlap_blow_up + (features_max_length - line_w)\n",
    "    text_image[line_xy:line_xy+overlap_blow_up, line_x:line_x+line_w,:] = line_text\n",
    "\n",
    "# put everything together\n",
    "hits_detail_image = numpy.concatenate((detail_timage, hits_detail_image), axis=1)\n",
    "dice_detail_image = numpy.concatenate((detail_timage, dice_detail_image), axis=1)\n",
    "hits_full_image = numpy.concatenate(\n",
    "    (hits_full_image, imfunc.image_rotate(text_image, 'left')), axis=0)\n",
    "dice_full_image = numpy.concatenate(\n",
    "    (dice_full_image, imfunc.image_rotate(text_image, 'left')), axis=0)\n",
    "text_filler = white_val * numpy.ones((text_image_x, text_image_x, 3,),\n",
    "    dtype=numpy.uint8)\n",
    "text_image = numpy.concatenate((text_image, text_filler), axis=0)\n",
    "hits_full_image = numpy.concatenate((text_image, hits_full_image), axis=1)\n",
    "dice_full_image = numpy.concatenate((text_image, dice_full_image), axis=1)\n",
    "\n",
    "# write and show image\n",
    "api.write_image(hits_detail_image, study_folder + 'EASY_PILOT_sp-hits_confusion_markup_cat.png')\n",
    "api.write_image(dice_detail_image, study_folder + 'EASY_PILOT_DICE_confusion_markup_cat.png')\n",
    "api.write_image(hits_full_image, study_folder + 'EASY_PILOT_sp-hits_confusion_markup_full.png')\n",
    "api.write_image(dice_full_image, study_folder + 'EASY_PILOT_DICE_confusion_markup_full.png')\n",
    "detail_combined = numpy.concatenate((hits_detail_image, dice_detail_image), axis=1)\n",
    "api.show_image_in_notebook(detail_combined, max_size=1024)\n",
    "api.show_image_in_notebook(hits_full_image, max_size=1024)\n",
    "api.show_image_in_notebook(dice_full_image, max_size=1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supplementary data\n",
    "\n",
    "## Table of ISIC images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S1_dict = {\n",
    "    'ISIC name': image_names,\n",
    "    'ISIC imageId': [img['_id'] for img in study.images],\n",
    "    'diagnosis': [study.meta_data['diagnosis'][img['name']] for img in study.images],\n",
    "    'exemplar feature': [study.meta_data['exemplar'][img['name']] for img in study.images],\n",
    "}\n",
    "for u in users:\n",
    "    S1_dict['diag_' + user_names[u]] = user_diagnosis[u]\n",
    "S1_study_images = pd.DataFrame.from_dict(S1_dict)\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    display(S1_study_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tables of dermoscopic features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S2_dermoscopic_features = pd.DataFrame.from_dict({\n",
    "    'Dermoscopic Feature': full_features_list,\n",
    "    'Total observations': [feature_markups[f] if f in feature_markups else 0\n",
    "        for f in full_features_list],\n",
    "    'In total images': [len(feature_in_images[f]) if f in feature_in_images else 0\n",
    "        for f in full_features_list],\n",
    "    'Orphans': [orphan_features[f] if f in orphan_features else 0\n",
    "        for f in full_features_list],\n",
    "    '2-RA': [len(agreed_2[f]) if f in agreed_2 else 0\n",
    "        for f in full_features_list],\n",
    "    'GS (3-RA)': [len(agreed_3[f]) if f in agreed_3 else 0\n",
    "        for f in full_features_list],\n",
    "    '4-RA': [len(agreed_4[f]) if f in agreed_4 else 0\n",
    "        for f in full_features_list],\n",
    "    '5-RA (FA)': [len(agreed_5[f]) if f in agreed_5 else 0\n",
    "        for f in full_features_list],\n",
    "})\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    display(S2_dermoscopic_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of discordant diagnoses with feature overlap > DICE=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S3_disdiag_sp_overlap_df = pd.DataFrame(disdiag_sp_overlap)\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    display(S3_disdiag_sp_overlap_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of features marked by each reader (+ #SPs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S4_features_by_image_and_user = pd.DataFrame.from_dict({\n",
    "    'ISIC name': image_names,\n",
    "    'ISIC imageId': [img['_id'] for img in study.images],\n",
    "    'diagnosis': [study.meta_data['diagnosis'][img['name']] for img in study.images],\n",
    "    'ICX6 features': user_feature_stats[0],\n",
    "    '6YB2 features': user_feature_stats[1],\n",
    "    'PKTZ features': user_feature_stats[2],\n",
    "    'Y63L features': user_feature_stats[3],\n",
    "    'WTPZ features': user_feature_stats[4],\n",
    "})\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    display(S4_features_by_image_and_user)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
